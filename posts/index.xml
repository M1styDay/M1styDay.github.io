<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on M1sty</title>
    <link>https://www.m1sty.com/posts/</link>
    <description>Recent content in Posts on M1sty</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.m1sty.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Applied AI in Business</title>
      <link>https://www.m1sty.com/2021/ed_2_applied-ai-in-business/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_2_applied-ai-in-business/</guid>
      <description>Applied AI in Business Curriculum Structure   Reading
 What is Machine Learning and the 5 components of AI systems（Read Chapter 1-3 of AI book）    Material
 Why use Machine Learning for Credit Scoring and deciding to give Loans? What are the 5 components of AI systems What are the 5 components of DoNotPay? Several FinTech Use Cases Summary Questions for reflection    Class 2 PPT Intro to Applied AI Four Pillars of Applied AI  Virtual Assistance Generating Insights Automation of Manual Processes Unlocking Unstructured Data  DoNotPay: Four Pillars of Applied AI?</description>
    </item>
    
    <item>
      <title>Intro Entrepreneurship Development</title>
      <link>https://www.m1sty.com/2021/ed_1_intro/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_1_intro/</guid>
      <description>Topic Topics covered
 The Business Model Canvas Customer Discovery Value Propositions &amp;amp; Minimal Viable Products Channels and Influencers Pivots Revenues and Pricing Models Resources, Activities and Partners Costs, Metrics, Financials and Fundraising Crowdfunding, Venture Capital Hong Kong incubators and accelerators Applied AI in Business The Applied AI Data Business Model Canvas The AI Startup Playbook  MVP Minimum Viable Product
Business Model Canvas Steve Blank Lean Startup Videos Value Proposition Videos</description>
    </item>
    
    <item>
      <title>Lecture 4：Top-k Queries</title>
      <link>https://www.m1sty.com/2021/atdm_top-k_1_content/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_top-k_1_content/</guid>
      <description>Top-k Queries Background Multidimensional Data  Flat relational tables Multimedia feature vectors Data warehouse data Spatial data Text documents  Attribute Types  Attributes of multidimensional tuples may have variable types  Ordinal (e.g., age, salary) Nominal categorical values (e.g., color, religion) Binary (e.g., gender, owns_property)   Basic queries: range, NN, similarity  Basic Queries  (Range) selection query  Returns the records that qualify a (multidimensional) range predicate Example:  Return the employees of age between 45 and 50 and salary above $100,000     Distance (similarity) query  Returns the records that are within a distance from a reference record.</description>
    </item>
    
    <item>
      <title>Tableau学习心得与模板分享</title>
      <link>https://www.m1sty.com/2021/visualization_tableau_map/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/visualization_tableau_map/</guid>
      <description>学习路径 Tableau 入门套件 简单了解Tableau的界面和基础操作。
https://www.tableau.com/zh-cn/learn/starter-kits
建议学习时间：两天
Tableau eLearning 分为基础、中级、高级，每一个专题都设置了练习题，根据指引完成练习题。
https://www.tableau.com/zh-cn/learn/training/elearning
ps：不建议在B站只看视频版，因为实际动手操作（练习题模块）是Tableau学习的关键。
建议学习时间：一周
Tableau Public 优秀模版积累，学习仪表板设计方式与页面逻辑。
https://public.tableau.com/zh-cn/s/
建议学习时间：长期积累
Tableau 白皮书 阅读有关数据可视化和 Tableau 最佳做法的深度信息。
https://www.tableau.com/zh-cn/learn/whitepapers
 推荐模板 Must Read Books By Black Authors 马克，以后可以用来做学习路径图谱
https://public.tableau.com/zh-cn/gallery/must-read-books-black-authors?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
Analyzing the Work of Bob Ross 可以用于关联规则分析的可视化展现
https://public.tableau.com/zh-cn/gallery/analyzing-work-bob-ross?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
Disney+ 交互设计非常有趣，可以用于运营数据展现
https://public.tableau.com/zh-cn/gallery/disney?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
PPP Loan Data 适用年终汇报
https://public.tableau.com/profile/dzifa.amexo#!/vizhome/PPPLoanData-MAD4Week7/Overview
Website Traffic Analysis 网站流量数据仪表板
https://public.tableau.com/profile/allison.wright4813#!/vizhome/WebsiteTrafficAnalysis_16032478866130/Webalytics-AnalyticsPackage
 结语 Tableau将原始数据转变为可操作、集成化、有意义的仪表板，有利于发现数据规律、找到数据问题、制定解决方案。
Tableau的学习最重要的就是动手操作，学习数据的逻辑、页面的布局，如何在有限的版面聚合更多的有效信息。而页面的美观只是其次的。</description>
    </item>
    
    <item>
      <title>Tutorial 4：Top-k Query Evaluation</title>
      <link>https://www.m1sty.com/2021/atdm_top-k_2_tutorial/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_top-k_2_tutorial/</guid>
      <description>TA &amp;amp; NRA Qustion A website posts information about apartments. Suppose that there are 10 apartments to be sold, together with their ratings($a_1$) and prices($a_2$), as listed in the table below. The website employs an aggregation function f = 0.6*$a_1$+ 0.4*$a_2$ to rank these apartments.
Q1) Write down two lists of apartments, in descending order of $a_1$ and $a_2$.
Q2) Use the TA algorithm to find the two best apartments in terms of f.</description>
    </item>
    
    <item>
      <title>Clusterings：Content</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_1_content/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_1_content/</guid>
      <description>Clusterings Background What is Cluster Analysis  Finding groups of objects such that the objects in a group will be similar (or related) to one another and different from (or unrelated to) the objects in other groups  Intra-cluster distances are minimized Inter-cluster distances are maximized   Notion of a Cluster can be Ambiguous  Applications of Cluster Analysis  Understanding  Group related documents for browsing, group genes and proteins that hav similar functionality, or group stocks with similar price fluctuations   Summarization  Reduce size of large data sets    What is not Cluster Analysis  Superviesd classification  Have class label information   Simple segmentation  Dividing students into different registration groups alpgabetically, by last name   Results of a query  Groupings are a result of an external specification   Graph partitioning  Some mutual relevance and synergy, but areas are not identical    Types of Clusterings Introduction   A clustering is a set of clusters</description>
    </item>
    
    <item>
      <title>Clusterings：Exercise</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_2_exercise/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_2_exercise/</guid>
      <description>Clusterings K-Means Algorithm Input Points Centroids Reclustering step 1 Recomputing centroids step 2 Recomputing the centroids step 3 Final Clustering K-Means++: Main Intuition Probaility distribution Sampling points Examples K-means- To understand why K-means++ use some randomness we compare it against the following algorithm which we call it K-means–:
The algorithm selects the first point randomly. Let t be any step of the algorithm, with 2 ≤ t &amp;lt; k. Let C be the set of points chosen at step t.</description>
    </item>
    
    <item>
      <title>Clusterings：Assignment</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_3_assignment/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_3_assignment/</guid>
      <description>Clusterings Theoretical exercises on K-means Qustion 1 Answer 1 Input Points and Set Centroids Input P1=(0,0), P2=(0,1/2), P3=(1,1/2), P4=(1,1), P5=(4,0), P6=(4,1), P7=(5,1)
Set P1=(0,0) and P4=(1,1) as centroids
Reclustering  STEP 1  For each point P2, P3, P5, P6, P7, determine the closest centroid
   d(a,P1) distance d(a,P4) distance     d(P2,P1) $\sqrt{ 0^2 + (\frac{1}{2})^2 }$ d(p2,p4) $\sqrt{ (\frac{1}{2})^2 + 1^2 }$   d(P3,P1) $\sqrt{ (\frac{1}{2})^2 + 1^2 }$ d(P3,P4) $\sqrt{ 0^2 + (\frac{1}{2})^2 }$   d(P5,P1) $\sqrt{ 0^2 + 4^2 }$ d(P5,P4) $\sqrt{ 1^2 + 3^2 }$   d(P6,P1) $\sqrt{ 1^2 + 4^2 }$ d(P6,P4) $\sqrt{ 0^2 + 3^2 }$   d(P7,P1) $\sqrt{ 1^2 + 5^2 }$ d(P7,P4) $\sqrt{ 0^2 + 4^2 }$    P2 is assigned to the red cluster</description>
    </item>
    
    <item>
      <title>Clusterings：Supplement</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_4_more/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_4_more/</guid>
      <description>Clusterings 《数据挖掘概念与技术》 第10章小结  簇是数据对象的集合,同一个簇中的对象彼此相似,而不同簇中的对象彼此相异。将物理或抽象对象的集合划分为相似对象的类的过程称为聚类。 聚类分析具有广泛的应用,包括商务智能、图像模式识别、Web搜索、生物学和安全。聚类分析可以作为独立的数据挖掘工具来获得对数据分布的了解,也可以作为在检测的簇上运行的其他数据挖掘算法的预处理步骤。 聚类是数据挖掘研究一个富有活力的领域。它与机器学习的无监督学习有关。 聚类是一个充满挑战的领域,其典型的要求包括可伸缩性、处理不同类型的数据和属性的能力、发现任意形状的簇、确定输入参数的最小领域知识需求、处理噪声数据的能力、增量聚类和对输入次 序的不敏感性、聚类高维数据的能力、基于约束的聚类,以及聚类的可解释性和可用性。 已经开发了许多聚类算法,这些算法可以从多方面分类,如根据划分标准、簇的分离性、所使用的相似性度量和聚类空间。本章讨论如下几类主要的基本聚类方法:划分方法、层次方法、基于密度的方法和基于网格的方法。有些算法可能属于多个类别。 划分方法首先创建k个分区的初始集合,其中参数k是要构建的分区数。然后,它采用选代重定位技术,试图通过把对象从一个簇移到另一个簇来改进划分的质量。典型的划分方法包括k-均值、k-中心点、 CLARANS。 层次方法创建给定数据对象集的层次分解。根据层次分解的形成方式,层次方法可以分为凝聚的 (自底向上)或分裂的(自顶向下)。为了弥补合并或分裂的僵硬性,凝聚的层次方法的聚类质量可以通过以下方法改进:分析每个层次划分中的对象连接(如Chameleon),或者首先执行微聚类(也就是把数据划分为“微簇”),然后使用其他的聚类技术,迭代重定位,在微簇上聚类(如BIRCH)。 基于密度的方法基于密度的概念来聚类对象。它或者根据邻域中对象的密度(例如DBSCAN),或者根据某种密度函数(例如DENCLUE)来生成簇。OPTICS是一个基于密度的方法,它生成数据聚类结构的一个增广序。 基于网格的方法首先将对象空间量化为有限数目的单元,形成网格结构,然后在网格结构上进行聚类。STNG是基于网格方法的一个典型例子,它基于存储在网格单元中的统计信息聚类。CLIQUE是基于网格的子空间聚类算法。 聚类评估估计在数据集上进行聚类分析的可行性和由聚类方法产生的结果的质量。任务包括评估聚类趋势、确定簇数和测定聚类的质量。  第11章小结  在传统的聚类分析中,对象被互斥地指派到一个簇中。然而,在许多应用中,需要以模糊或概率方式把一个对象指派到一个或多个簇。模糊聚类和基于概率模型的聚类允许一个对象属于一个或多个 簇。划分矩阵记录对象属于簇的隶属度。 基于概率模型的聚类假定每个簇是一个有参分布。使用待聚类的数据作为观测样本,我们可以估计簇的参数 混合模型假定观测对象是来自多个概率簇的实例的混合。从概念上讲,每个观测对象都是通过如下方法独立地产生的:首先根据簇概率选择一个概率簇,然后根据选定簇的概率密度函数选择一个样本。 期望最大化(EM)算法是一个框架,它通近最大似然或统计模型参数的后验概率估计。EM算法 可以用来计算模糊聚类和基于概率模型的聚类。 高维数据对聚类分析提出了一些挑战,包括如何对高维簇建模和如何搜索这样的簇。 高维数据聚类方法主要有两类:子空间聚类方法和维归约方法。子空间聚类方法在原空间的子空间中搜索簇。例子包括子空间搜索方法、基于相关性的聚类方法和双聚类方法。维归约方法创建较低维的新空间,并在新空间搜索簇。 双聚类方法同时聚类对象和属性。双簇的类型包括具有常数值、行/列常数值、相干值、行/列相干 演变值的双簇。双聚类方法的两种主要类型是基于最优化的方法和枚举方法。 谱聚类是一种维归约方法。其一般思想是使用相似矩阵构建新维。 聚类图和网络数据有许多应用,如社会网络分析。挑战包括如何度量图中对象之间的相似性和如何为图和网络数据设计聚类方法。 测地距是图中两个顶点之间的边数,它可以用来度量相似性。另外,像社会网络这样的图的相似性也可以用结构情境和随机游走度量。SimRank是一种基于结构情境和随机游走的相似性度量。 图聚类可以建模为计算图割。最稀疏的割导致好的聚类,而模块性可以用来度量聚类质量。 SCAN是一种图聚类算法,它搜索图,识别良连通的成分作为簇。 约束可以用来表达具体应用对聚类分析的要求或背景知识。聚类约束可以分为实例、簇和相似性度量上的约束。实例上的约束可以是必须联系约束和不能联系约束。约束可以是硬性的或软性的。 聚类的硬性约束可以通过在聚类指派过程严格遵守约束而强制实施。软性约束聚类可以看做一个优化问题。可以使用启发式方法加快约束聚类的速度。  </description>
    </item>
    
    <item>
      <title>Clusterings：Practise(K-means)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</guid>
      <description>Clusterings K-means聚类的思想和原理 模型介绍 对于监督的数据挖掘算法而言，数据集中需要包含标签变量（即因变量y的值）。但在有些场景下，并没有给定的y值，对于这类数据的建模，一般称为无监督的数据挖掘算法，最典型的当属聚类算法。
K-means聚类算法利用距离远近的思想将目标数据为制定的k个簇，进而使样本呈现簇内差异小，簇间差异大的特征。
聚类步骤  从数据中随机挑选k个样本点作为原始的簇中心 计算剩余样本与簇中心的距离，并把各样本标记为离k个簇中心最近的类别 重新计算各簇中样本点的均值，并以均值作为新的k个簇中心 不断重复第二步和第三步，直到簇中心的变化趋于稳定，形成最终的k个簇  原理介绍 最佳K值的选择 拐点法 簇内离差平方和拐点法的思想很简单，就是在不同的k值下计算簇内利差平方和，然后通过可视化的方法找到“拐点”所对应的k值。当折线图中的斜率由大突然变小时，并且之后的斜率变化缓慢，则认为突然变化的点就是寻找的目标点，因为继续随着簇数k的增加，聚类效果不再有大的变化。
def k_SSE(X,cluster): # 选择连续的K种不同的值 K = range(1,clusters+1) # 构建空列表用于存储总的簇内离差平方和 TSSE = [] for k in K: # 用于存储各个簇内离差平方和 SSE = [] kmeans = KMeans(n_clusters = k) Kmeans.fit(X) # 返回簇标签 labels = Kmeans.labels_ # 返回簇中心 centers = Kmeans.cluster_centers_ # 计算各簇样本的离差平方和，并保存到列表中 for label in set(labels): SEE.append(np.sum((X.loc[labels == label,]-centers[label,:])**2)) # 计算总的簇内离差平方和 TSSE.append(np.sum(SSE)) 轮廓系数法 该方法综合考虑了簇的密集性和分散性两个信息，如果数据集被分割为理想的k各簇，那么对应的簇内样本会很密集，而簇间样本会很分散，轮廓系数的计算公式可以表示为：
其中，a(i)体现了簇内的密集性，代表样本i与同簇内其他样本点距离的平均值；b(i)反映了簇间的分散性，它的计算过程是，样本i与其他非同簇样本点距离的平均值，然后从平均值中挑选出最小值。
当S(i)接近于-1时，说明样本i分配的不合理，需要将分配到其他簇中；当S(i)近似为0时，说明样本i落在了模糊地带，即簇的边界处；当S(i)近似为1时，说明样本i的分配是合理的。
# 构造自定义函数 def k_silhouette(X,clusters): K = range(2,clusters+1) # 构建空列表，用于存储不同簇数下的轮廓系数 S = [] for k in K: kmeans = KMeans(n_clusters = k) Kmenas.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(DBSCAN)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</guid>
      <description>Clusterings 熟悉密度聚类中的几个概念 模型介绍   Kmeans聚类存在两个致命缺点，一是聚类效果容易受到异常样本点的影响;二是该算法无法准确地将非球形样本进行合理的聚类。
  基于密度的聚类则可以解决非球形簇的问题，“密度”可以理解为样本点的紧密程度，如果在指定的半径领域内，实际样本量超过给定的最小样本量阈值，则认为是密度高的对象，就可以聚成一个簇。
  概念讲解  点的领域：在某点p处，给定其半径e后，所得到的覆盖区域 核心对象：对于给定的最少样本量MinPts而言，如果某点p的e领域内至少包含MinPts个样本点，则点p就为核心对象。 直接密度可达：假设点p为核心对象，且在点p的e领域内存在点q，则从点p出发到点q是直接密度可达的。 密度可达：假设存在一系列的对象链$P_1$,$P_2$,&amp;hellip;,$P_n$，如果$p_i$是关于半径e和最少样本点MinPts的直接密度可达$P_(i+1)$，则p1密度可达$P_n$。(i = 1,2,&amp;hellip;n) 密度相连：假设点o为核心对象，从点o出发得到两个密度可达点p和点q，则称点p和点q是密度相连的。 聚类的簇：簇包含了最大的密度相连所构成的样本点。 边界点：假设点p为核心对象，在其领域内包含了点b，如果点b为非核心对象，则称其为点p的边界点。 异常点：不属于任何簇的样本点。  理解密度聚类的过程 步骤讲解  为密度聚类算法设置一个合理的半径以及半径领域内所包含的最少样本量MinPts。 从数据集中随机挑选一个样本点p，检验其在半径领域内是否包含制定的最少样本量，如果包含就将其定性为核心对象，并构成一个簇C；否则，重新挑选一个样本点。 对于核心对象p所覆盖的其他样本点q，如果点q对应的半径领域内仍然包含最少样本量MinPts，就将其覆盖的样本点统统归于簇C。 重复步骤（3），将最大的密度相连所包含的样本点聚为一类，形成一个大簇。 完成步骤（4）后，重新回到步骤（2），并重复步骤（3）和（4），直到没有新的样本点可以生成新簇时算法结束。  函数介绍 cluster.DBSCAN(eps=0.5, min_samples=5, metric=‘euclidean’, p=None)   eps:用于设置密度聚类中的e领域，即半径，默认为0.5。
  min_samples:用于设置e领域内最少的样本量，默认为5。
  metric:用于指定计算点之间距离的方法，默认为欧氏距离 。
  p:当参数metric为闵可夫斯基(&amp;lsquo;minkowski&amp;rsquo;)距离时，p=1，表示计算点之间的曼哈顿距离;p=2，表示计算点之间的欧式距离；该参数的默认值为2。
  密度聚类相比Kmeans聚类的优势 球形簇的情况 K-means DBSCAN 非球形簇的情况 K-means DBSCAN DBSCAN难确定半径和MinPts
密度聚类的应用实战 利用自定义球形簇数据对比DBSCAN和K-means # 导入第三方模块 import pandas as pd import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(Hierarchical Clusterings)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</guid>
      <description>层次聚类 理论说明 https://blog.csdn.net/shulianghan/article/details/105960850
https://blog.csdn.net/liujh845633242/article/details/103679724
层次聚类更适合小样本；K-Means更适合大样本。
代码实现 # 导入第三方模块 import pandas as pd import numpy as np from sklearn.datasets import make_blobs import matplotlib.pyplot as plt import seaborn as sns from sklearn import cluster # 构造两个球形簇的数据样本点 X,y = make_blobs(n_samples = 2000, centers = [[-1,0],[1,0.5]], cluster_std = [0.2,0.45], random_state = 1234) # 将模拟得到的数组转换为数据框，用于绘图 plot_data = pd.DataFrame(np.column_stack((X,y)), columns = [&amp;#39;x1&amp;#39;,&amp;#39;x2&amp;#39;,&amp;#39;y&amp;#39;]) # 绘制散点图（用不同的形状代表不同的簇） sns.lmplot(&amp;#39;x1&amp;#39;, &amp;#39;x2&amp;#39;, data = plot_data, hue = &amp;#39;y&amp;#39;,markers = [&amp;#39;^&amp;#39;,&amp;#39;o&amp;#39;], fit_reg = False, legend = False) # 显示图形 plt.</description>
    </item>
    
    <item>
      <title>Association：Content(1)</title>
      <link>https://www.m1sty.com/2021/dm_association_1_content1/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_1_content1/</guid>
      <description>Frequent Itemsets and Association Rules Market Baskets The Market-Basket Model   A large set of items, e.g., things sold in a supermarket.
  A large set of baskets, each of which is a small set of the items, e.g., the things one customer buys on one day.
  A general many-many mapping (association) between two kinds of things.
  The technology focuses on common events, not rare events (“long tail”).</description>
    </item>
    
    <item>
      <title>Association：Content(2)</title>
      <link>https://www.m1sty.com/2021/dm_association_1_content2/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_1_content2/</guid>
      <description>Improvements to A-Priori PCY Algorithm Introdution  Main observation: during pass 1 of A-priori, most memory is idle. Use that memory to keep additional info to improve storage during pass 2 of A-priori. Passes &amp;gt; 2 are the same as in A-Priori.  Pass 1  Use a hash function which &amp;ldquo;bucketizes&amp;rdquo; item pairs, that is, maps them to integers in $[1,k]$. Each &amp;ldquo;bucket&amp;rdquo; i in $[1,k]$ is associated with a counter $c_i$.</description>
    </item>
    
    <item>
      <title>数据指标体系搭建（以PY项目为例）【施工中……】</title>
      <link>https://www.m1sty.com/2021/project_data-index_content/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/project_data-index_content/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Association：Exercise</title>
      <link>https://www.m1sty.com/2021/dm_association_2_exercise/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_2_exercise/</guid>
      <description>Naive Algorithm Pass 1 Support treshold：2
Pass 2 Support treshold：2
Pass 3 Support treshold：2
A-priori Algorithm Pass 1 Pass 2 Pass 3 PCY Algorithm Input Data Pass 1 Pass 2 The remaining passes The remaining passes are the same of A-priori
SON Algorithm Introduction Let s be the support threshold:
 Pass 1:  Divide the dataset into k chunks, let $p_i$ be such that the ith chunk contains a fraction of pi of the input dataset.</description>
    </item>
    
    <item>
      <title>Association：Assignment</title>
      <link>https://www.m1sty.com/2021/dm_association_3_assignment/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_3_assignment/</guid>
      <description>Association Frequent Itemsets Qustion 1 Qustion 1-1  Table 1 shows a list of baskets as well as the items they contain. For example, this could be the set of products bought by each customer during a single trip to a grocery store. Using the A-priori algorithm, find all frequent itemsets with support threshold 0.4 (i.e. in this example they occur at least 40% of 7 times, i.e. at least three times.</description>
    </item>
    
    <item>
      <title>Association：Supplement</title>
      <link>https://www.m1sty.com/2021/dm_association_4_more/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_4_more/</guid>
      <description>Association 《数据挖掘概念与技术》 第6章小结  大量数据中的频繁模式、关联和相关关系的发现在选择性销售、决策分析和商务管理方面是有用的。一个流行的应用领域是购物篮分析，通过搜索经常一起(或依次)购买的商品的集合，研究顾客的购买习惯。 关联规则挖掘首先找出频繁项集(项的集合，如A和B，满足最小支持度阈值，或任务相关元组的百分比)，然后，由它们产生形如A→B的强关联规则。这些规则还满足最小置信度阈值(预定义的、在满足A的条件下满足B的概率)。可以进一步分析关联，发现项集A和B之间具有统计相关性的相关规则。 对于频繁项集挖掘，已经开发了许多有效的、可伸缩的算法，由它们可以导出关联和相关规则。这些算法可以分成三类：(1)类Apriori算法；(2)基于频繁模式增长的算法，如FP-growth；(3)使用垂直数据格式的算法。 Apriori算法是为布尔关联规则挖掘频繁项集的原创性算法。它逐层进行挖掘，利用先验性质：频繁项集的所有非空子集也都是频繁的。在第k次迭代(k≥2)，它根据频繁(k-1)项集形成k项集候选，并扫描数据库一次，找出完整的频繁k项集的集合L。使用涉及散列和事务压缩技术的变形使得过程更有效。其他变形包括划分数据(对每分区挖掘,然后合并结果)和抽样数据 (对数据子集挖掘)。这些变形可以将数据扫描次数减少到一两次。 频繁模式增长(FP-growth)是一种不产生候选的挖掘频繁项集方法。它构造一个高度压缩的数据结构(FP树)，压缩原来的事务数据库。与类Apriori方法使用产生-测试策略不同，它聚焦于频繁模式(段)增长，避免了高代价的候选产生，可获得更好的效率。 使用垂直效据格式挖掘频繁模式(ECLAT)将给定的、用TID-项集形式的水平数据格式事务数据集变换成项-TID集合形式的垂直数据格式。它根据先验性质和附加的优化技术(如differ)通过取TID-集的交，对变换后的数据集进行挖掘。 并非所有的强关联规则都是有趣的。因此,应当用模式评估度量来扩展支持度-置信度框架，促进更有趣的规则的挖掘，以产生更有意义的相关规则。一种度量是零不变的，如果它的值不受零事务（即不包含所考虑项集的事务）的影响。在许多模式评估度量中,我们考察了提升度、X、全置信度、最大置信度、 Kuczynski和余弦，并且说明只有后4种是零不变的。我们建议把Kuczynski度量与不平衡比一起使用，提供项集间的模式联系。  第7章小结  频繁模式挖掘的研究范围已经远远超第6章介绍的挖掘频繁项集和关联的基本概念和方法。本章给出了一个该领域的路线图，其中主题按照可挖掘的模式和规则的类型、挖掘方法和应用组织。 除了挖掘基本的频繁项集和关联外，还可以挖掘高级的模式形式，如多层关联和多维关联、量化关联规则、稀有模式和负模式。还可以挖掘高维模式、压缩的或近似的模式。 多层关联涉及多个抽象层中的数据（例如，“买计算机”和“买便携式计算机”）。这些可以使用多个最小支持度阀值挖掘。多维关联包含多个维。挖掘这种关联的技术因如何处理重复谓词而异。量化关联规则涉及量化属性。离散化、聚类和揭示异常行为的统计分析可以与模式挖掘过程集成在一起。 稀有模式很少出现但特别有趣。负模式是其成员呈现负相关行为的模式。应该小心定义负模式，考虑零不变性性质。稀有模式和负模式可能凸显数据的异常行为，这可能很有趣。 基于约束的挖掘策略可以用来引导挖掘过程，挖掘与用户只管一致或满足某些约束的模式。许多用户制定的约束都可以推进到挖掘过程中。约束可以分为模式剪枝约束和数据剪枝约束，这些约束的性质包括单调性、反单调性、数据反单调性和简洁性。具有这些性质的约束可以正确地集成到数据挖掘过程中。 已经为高维空间中的模式挖掘开发了一些方法，包括为挖掘维数很大但元组很少的数据集（如微阵列数据）的基于行枚举的模式增长方法，以及通过模式融合方法挖掘巨型模式（即非常长的模式）。 为了减少挖掘返回的模式数量，我们可以代之以挖掘压缩模式或近似模式。压缩模式可以通过基于聚类概念定义代表模式来挖掘，而近似模式可以通过提取感知冗余的top-k模式（即k个代表模式的小集合，它们不仅具有高显著性，而且相互之间低冗余）来挖掘。 可以产生语义注解，帮助用户理解发现的频繁模式的含义。这样的注解蕾丝词典，提供关于项的语义信息。这些信息包括语境提示符（例如，指示模式语境的术语）/最具代表性的事务（例如，包括该术语的片段或语句）和语义最相似的模式。这种注解从不同角度提供了模式的语境视图，有助于理解它们。 频繁模式挖掘具有形形色色的应用，涵盖从基于模式的数据清理，到基于模式的分类、聚类、离群点或异常分析。  </description>
    </item>
    
    <item>
      <title>Association：Practise</title>
      <link>https://www.m1sty.com/2021/dm_association_5_practise/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_5_practise/</guid>
      <description>#we run apriori on the order_data.csv file import math import pandas as pd from mlxtend.preprocessing import TransactionEncoder from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules data = pd.read_csv(r&amp;#34;order_data.csv&amp;#34;,delimiter=&amp;#34; &amp;#34;,header=None) #preprocessing: change to one hot encoding so as to be able to use apriori from mlxtend d=data.values.tolist() #removing nan values for i in range(len(d)): j=0 while(True): if (type(d[i][j])==float and math.isnan(d[i][j])) : del d[i][j] j-=1 j+=1 if (j&amp;gt;len(d[i])-1): break te = TransactionEncoder() te_ary = te.</description>
    </item>
    
    <item>
      <title>Pre-processing</title>
      <link>https://www.m1sty.com/2021/dm_0_clear/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_0_clear/</guid>
      <description>常用工具 numpy 构建数组   Numpy中常用的数据结构是ndarray格式
  使用array函数创建，语法格式为array(列表或元组)
  可以使用其他函数例如arange、linspace、zeros等创建
  import numpy as np arr1 = np.array([-9,7,4,3]) np.arange(0,10,1) np.linspace(1,10,10) np.zeros (1,5) 常用方法   常用方法名称：ndim、shape、size、dtype、运算
  数组访问方法：array$[行，列]$
  排序  sort函数：从小到大进行排序 argsort函数：返回的是数据中, 从小到大的索引值  s = np.array([1,2,3,4,3,1,2,2,4,6,7,2,4,8,4,5]) np.sort(s) np.argsort(s) 搜索 np.where np.extract np.where(s&amp;gt;3,1,-1) np.extract(s&amp;gt;3,s) pandas 构建数组（series） series1 = pd.Series([2.8,3.01,8.99,8.59,5.18]) series2 = pd.Series([2.8,3.01,8.99,8.59,5.18],index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e&amp;#39;],name =&amp;#39;这是一个series’)  series3 = pd.Series(np.array((2.8,3.10,8.99,8.59,5.18)),index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e’]) series4 = pd.Series({&amp;#39;北京&amp;#39;:2.8,&amp;#39;上海&amp;#39;:3.01,&amp;#39;广东&amp;#39;:8.99,&amp;#39;江苏&amp;#39;:8.59,&amp;#39;浙江&amp;#39;:5.18}) 构建数组（dataframe） list1 = [[&amp;#39;张三&amp;#39;,23,&amp;#39;男&amp;#39;],[&amp;#39;李四&amp;#39;,27,&amp;#39;女&amp;#39;],[&amp;#39;王二&amp;#39;,26,&amp;#39;女&amp;#39;]]#使用嵌套列表 df1 = pd.</description>
    </item>
    
    <item>
      <title>SQL面试必会50题_题解</title>
      <link>https://www.m1sty.com/2020/database_sql_50/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_50/</guid>
      <description>材料 题源+数据 SQL面试必会50题
表关系  题解 01-10 1. 查询课程编号为“01”的课程比“02”的课程成绩高的所有学生的学号 SELECT st.s_id, a.s_score, b.s_score FROM student st INNER JOIN (SELECT s_id, s_score FROM score WHERE c_id = &amp;#34;01&amp;#34;) as a on a.s_id = st.`s_id` INNER JOIN (SELECT s_id, s_score FROM score WHERE c_id = &amp;#34;02&amp;#34;) as b on b.s_id = st.`s_id` WHERE a.s_score &amp;gt; b.s_score; 2. 查询平均成绩大于60分的学生的学号和平均成绩 SELECT distinct s_id, AVG(s_score) as avg1 FROM score Group by S_id having avg1 &amp;gt; 60 3.</description>
    </item>
    
    <item>
      <title>SQL语句复习</title>
      <link>https://www.m1sty.com/2020/database_sql_notes2/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_notes2/</guid>
      <description>DDL &amp;amp; DML 库操作 创建数据库 CREATE DATABASE database-name
删除数据库 drop database dbname
分离数据库 sp_detach_db
附加数据库 sp_attach_db （后接表明，附加需要完整的路径名）
修改数据库名称 sp_renamedb &amp;lsquo;old_name&amp;rsquo;, &amp;lsquo;new_name&amp;rsquo;
表操作 创建新表 create table tabname(col1 type1 [not null] [primary key],col2 type2 [not null],..)
根据已有的表创建新表 A：create table tab_new like tab_old
B：create table tab_new as select col1,col2… from tab_old definition only
删除表 drop table tabname
增加列 Alter table tabname add column col type
添加/删除主键 Alter table tabname add primary key(col)
Alter table tabname drop primary key(col)</description>
    </item>
    
    <item>
      <title>SQL基础知识</title>
      <link>https://www.m1sty.com/2020/database_sql_notes/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_notes/</guid>
      <description>表操作 创建表 create table 表名（字段名称 字段类型 约束，……） 字符类型  character 字符串  char(size) 保存固定长度的字符串 varchar(n) 可变长度的字符_最多8000个字符 text 可变长度的字符串_最多2GB字符数据   unicode 字符串  nchar(n) 固定长度的Unicode数据_最多4000个字符 nvarchar(n) 可变长度的Unicode数据_最多4000个字符 ntext 可变长度的Unicode数据_最多2GB字符数据   Binary 类型  bit 允许0/1/null binary(n) 固定长度的二进制数据_最多8000字节 varbinary(n) 可变长度的二进制数据_最多8000字节 image 可变长度的二进制数据_最多2GB   Number 类型  tinyint 允许从0到255的所有数字 int 允许从-2,147,483,648到2,147,483,647的所有数字_占4字节 bigint -9,223,372,036,854,775,808到9,223,372,036,854,775,807范围内数字_占8字节 float 从-1.79E+308到1.79E+308的浮动精度数字数据 real 从-3.40E+38到3.40E+38的浮动精度数字数据 money 10进制货币数据   Date 类型  datetime 从1753年1月1日到9999年年12月31日，精度为3.33毫秒_8bytes date 仅储存日期。从0001年1月1日到9999年12月31日_3bytes   其他数据类型  uniqueidentifler 存储全局标识符（GUID） xml 存储XML格式化数据_最多2GB cursor 存储对用于数据库操作的指针的引用   常见的字符类型选择  字符类型建议采用varchar/nvarchar数据类型 全额货币建议采用money数据类型 自增长标识建议采用bigint数据类型（int类型限制） 时间类型建议采用datetime数据类型 尽量不用text、ntext、image 尽量不用xml、varchar(max)、nvarchar(max)    不同数据库数据字符类型区别  https://www.</description>
    </item>
    
    <item>
      <title>数据分析师学习路径</title>
      <link>https://www.m1sty.com/2020/overview_data-analyst_map/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/overview_data-analyst_map/</guid>
      <description></description>
    </item>
    
    <item>
      <title>牛客网数据库_错题集</title>
      <link>https://www.m1sty.com/2020/database_sql_nowcoder/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_nowcoder/</guid>
      <description>语法问题 删除 如果要从数据库中删除触发器，应该使用SQL语言的命令：（B）
 A.DELETE TRIGGER B.DROP TRIGGER C.DISABLE TRIGGER D.REMOVE TRIGGER  Notes: 删除触发器: DROP TRIGGER &amp;lt;触发器名&amp;gt; ON &amp;lt;表名&amp;gt;
Drop:删除数据表或数据库，或删除数据表字段
Remove:删除数据库文件
Truncate：删除数据表中的数据（仅数据表中的数据，不删除表）
delete和drop最本质的区别在于，delete是数据操纵语言，即DML，而drop是数据定义语言，即DDL。因此，当我们需要删除或者创建一个东西，如表/视图/触发器等等，用的是数据定义语言。当我们对已经存在的表/视图/触发器进行修改/更新时，用的是数据操纵语言。以表为例，如果你不想将表真的删掉，只是想删除其中某些特定的记录，则应该用delete，此时，表的其他数据以及表的结构还在。
权限 收回从u1创建表的权限：（B）
 A.revoke create table to u1 B.revoke create table from u1 C.revoke create table from u1 with grant option D.deny create table to u1  Notes: with grant option 权限传递 使用这个子句时将允许用户将其权限分配给他人
子查询： 在SQL语言中，子查询是： (D)
 A.返回单表中数据子集的查询语言 B.选取多表中字段子集的查询语句 C.选取单表中字段子集的查询语句 D.嵌入到另一个查询语句之中的查询语句  Notes: 子查询本质上是嵌套进其他SELECT,UPDATE,INSERT,DELETE语句的一个被限制的SELECT语句。
子查询也可以嵌套在其他子查询中,这个嵌套最多可达32层。子查询也叫内部查询(Inner query)或者内部选择(Inner Select),而包含子查询的查询语句也叫做外部查询（Outter)或者外部选择(Outer Select)。</description>
    </item>
    
    <item>
      <title>Web 2.0：A Strategy Guide</title>
      <link>https://www.m1sty.com/2020/business_book_web-2.0-a-strategy-guide/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/business_book_web-2.0-a-strategy-guide/</guid>
      <description>Web 2.0: A Strategy Guide Chapter 1 Users Create Value Flickr and Collective User Value   What is Web2.0
Web 2.0 turbocharges network effects because online users are no longer limited by how many things they can find, see, or down- load off the Web, but rather by how many things they can do, interact, combine, remix, upload, change, and customize for them- selves. This online DIY self-expression benefits businesses and other users, not just individual uploaders.</description>
    </item>
    
  </channel>
</rss>
