<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on M1sty</title>
    <link>https://www.m1sty.com/posts/</link>
    <description>Recent content in Posts on M1sty</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.m1sty.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lecture1：Business Order; Chaos and Complexity</title>
      <link>https://www.m1sty.com/2021/eb_lecture1_business-order-chaos-and-complexity/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/eb_lecture1_business-order-chaos-and-complexity/</guid>
      <description>Curriculum structure  Transition from industrial revolution to digital revolution Information as an experience good Economics of information Chaos and complexity e-Business transformation cycle  Text Book: Chapter 1 Introduction Chapter 1 Change and transformation in business explores past attempts at organisational transformation and considers why many of these efforts have been unsuccessful. Particular attention is given to the hope placed in the Total Quality Management (TQM) and Business Process Reengineering (BPR) movements as an elixir for organisational problems.</description>
    </item>
    
    <item>
      <title>AB Test实验全知识</title>
      <link>https://www.m1sty.com/2021/business_web_ab-test/</link>
      <pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/business_web_ab-test/</guid>
      <description>前言 A/B实验的目的在于通过科学的实验设计、采样样本代表性、流量分割与小流量测试等方式来获得具有代表性的结论，并确信该结论可推广到全部流量。目前已广泛用于推荐算法、产品交互设计、广告投放、产品功能迭代、运营策略等方方面面，在评估资源使用ROI最常用且最为准确的方法也是A/B实验。
AB test基础知识 在开始进行A/B实验之前需要了解一些关于A/B测试的基础知识，包含流量的正交与互斥、实验分组、假设检验、P值、显著性水平α、置信区间、统计功效等。
正交试验与互斥实验 一个产品的流量是有限的，但是A/B实验的需求是大量的，因此在进行实验前需要确认流量必须互斥还是可以进行正交。正交实验指每个独立实验为一层，层与层之间流量是正交的，一份流量经过每层实验时，都会再次随机打散，且随机效果离散。互斥实验指实验在同一层拆分流量，且不论如何拆分，不同组的流量是不重叠的，如下图所示：
  域1和域2流量进行了拆分，此时域1和域2是互斥的。一般是有相互干扰的实验需要进行流量互斥，比如同样是发促销券类活动，只是不同的业务团队发放的，那么域1和域2的流量就要拆分开，避免互相进行干扰，影响实验最终结果。
  流量流过域2中的B1层、B2层、B3层时，流量都是与域2的流量相等，此时B1层、B2层、B3层的流量是正交的，比较典型的B1层、B2层、B3层是UI层、搜索结果层、广告结果层，这几层基本上是没有任何的业务关联度的，即使共用相同的流量（流量正交）也不会对实际的业务造成结果。
  值得注意的是，流量流过域2中的B1层时，又把B1层分为了B1-1，B1-2，B1-3，此时B1-1，B1-2，B1-3之间又是互斥的。
  实验分组 一般来说，至少有1个实验组A和1个对照组B，但是随着A/B测试的应用越来越广泛，并不局限于只有1个实验组A和1个对照组B，可能会有实验组A1、实验组A2和对照组B，甚至更多的实验组同时验证不同策略的效果。比如在实际的运营工作中，需要评估某个券的效果，这时候设置了3个组：
  实验组1：用规则发券，所有目标用户群发放满200-20的品类券
  实验组2：走模型策略，基于用户的标签属性发放不同门槛-面额的券，比如有人发放满150-10，有人发放满300-30
  对照组：不进行任何发券动作
  这样，根据实验组1和对照组进行比较能得出规则发券的效果，实验组2和对照组进行比较能得出模型策略发券效果，从而得出走模型策略相较于规则发券效果提升了多少。
假设检验 假设检验是先对总体参数提出一个假设值，然后利用样本信息判断这一假设是否成立。需要了解假设检验中的两个假设、两类错误。
  两个假设
 原假设H0：实验中想反对的假设 备择假设H1：实验中想予以支持的假设    两类错误
 第一类错误：弃真错误，当原假设为真时拒绝原假设 第二类错误：取伪错误，当原假设为假时未拒绝原假设    假设检验中的P值 P值即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法所得到的P值，一般以P&amp;lt;0.05 为有统计学差异。
假设检验中的显著性水平α 显著性水平是估计总体参数落在某一区间内，可能犯错误的概率，用α表示。小概率标准α和P值的关系如下：
 如果P≤α，那么拒绝原假设 如果P&amp;gt;α，那么不能拒绝原假设  Z检验 检验方法有t检验、Z检验、χ2检验和F检验。在A/B实验中，主要是对样本均值进行检验，所以用t检验和Z检验。在样本数量比较大情况下，采用Z检验，A/B实验中双样本Z检验公式如下：
 t检验：t检验常用于总体正态分布、总体方差未知或独立小样本平均数的显著性检验、平均数差异显著性检验。 Z检验：Z检验常用于总体正态分布、方差已知或独立大样本的平均数的显著性和差异的显著性检验。  置信区间 置信区间是用来对一个概率样本的总体参数进行区间估计的样本均值范围，它展现了这个均值范围包含总体参数的概率，这个概率称为置信水平。置信水平代表了估计的可靠度，一般来说使用95%的置信水平进行区间估计。置信区间可以辅助确定版本间是否有存在显著差异的可能性：如果置信区间上下限的值同为正或负，认为存在有显著差异的可能性；如果同时有负值和正值，那么则认为不存在有显著差异的可能性。
根据统计学的中心极限定理，样本均值的抽样分布呈整体分布，因此通过下面的公式可以计算出两个总体均值差的95%置信区间：
统计功效 当两个不同版本之间存在显著差异时，实验能正确做出存在差异判断的概率。可以理解为有多少的把握认为版本之间有差别。该值越大则表示概率越大、功效越充分。一般来说，设定最低的统计功效值为80%，统计功效的计算如下：</description>
    </item>
    
    <item>
      <title>ROI思维</title>
      <link>https://www.m1sty.com/2021/business_web_roi/</link>
      <pubDate>Wed, 07 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/business_web_roi/</guid>
      <description>ROI思维 ROI指的就是投入回报率。举个简单的例子，我们经营一个剧集，这个剧集分发在AB不同的场景里面，在曝光量的量级基本相同的情况下，A场景的转化率远远高于B场景，那么这就说明A场景的投入回报率要高于B场景，这样我们就可以通过调整AB两个场景的投入来获得更高效的回报并提升资源的利用率。
ROI 指标 曝光-转化体系  基准值：各指标的及格线 pv：page view uv：user view 曝光pv：访问次数，可以反映资源给到的支持，首屏位置的曝光pv一般是页面最高的，如果能固定在这个位置的资源，那么就可以获得较高的曝光pv 点击pv：点击次数 CTR（pv）=点击pv/曝光pv，可以反映在这个位置上的内容推广物料的转化能力，如果pv点击率低于基准值则说明物料的转化能力弱，投入产出率低，产出的转化配不上给到的资源 曝光uv：访问用户数，同样可以反映资源给到的支持 点击uv：点击用户数 CTR（uv）=点击uv/曝光uv，可以反映在这个位置上的内容推广物料对单个用户的转化能力 过曝：累积过曝：曝光pv/曝光uv≥5时，这个标准不太一样有些以3为标准，有些以4或5为标准，这个指标单个物料是给单个用户曝光了多少次，一般展示频次控制在4次是能够达到最高的转化效能的，曝光过多往往会起到反效果； 粗放过曝：CTR没有达到基准值，可能是物料的吸引力不够强，也可能是曝光命中的准确度不高，一定程度上造成了资源浪费，出现这种情况可以调整为更为精准的定向曝光。 欠曝：欠曝与过曝相反。  拉新-留存-促活-承接体系  拉新：拉新主要是为内容拉入新用户，分为站外新用户和站内新用户，一般增量内容（比如新的题材、IP内容、热搜内容）更关注站外的拉新能力 新用户占比：新用户数/总用户数，体现内容拉新能力的重要指标。 时长：用户内容消费的时长 DAU：日活用户数，该指标可以看到内容在时间周期上的流量变化情况。 次日/3日/7日留存率：当天流入用户中第N天还登录的用户数/当天天新增总用户数，该指标是观测用户阶段性留存的重要依据，一般也可反向观测弃看率，留存率高则说明内容有持续的留存效能。 互动率：参与互动的用户数/收视用户数，这个指标可以看到该内容是否吸引用户参与讨论或者分享。 互动热词：一般以词云的方式呈现，排名靠前的热词在一定程度上代表用户共同的情感反馈，这些热词可以用作站外宣发和站内看点用。 承接：新热内容都是有生命周期的，这些内容即将结束的时候，需要用相关性比较强的内容产品将这部分用户留存住，这个过程就是承接，一般在内容即将收官时或中间的更新空档会进行种草预埋，如果是承接给未上线的新内容则需要进一步引导预约，观测预约用户的特征，决定是否能够完全承接旧内容，如果不能则需用不同内容分层承接，当新热内容无法满足承接需求时，也可用片库的内容进行承接。    图中简单罗列了内容承接的特征依据，除了性别和年龄外，可以参考的特征指标还有地域、受教育程度等人口统计学特征和类型偏好、情节偏好、明星偏好等行为特征。其中承接的效能主要观测两个指标，一个是用户重合度，一个是重合用户特征。
  用户重合度：（X内容用户∩Y内容用户）/（X内容用户∪Y内容用户），这个可以看到X内容对Y内容用户承接的能力，比如B1内容和A1内容的用户重合度是10%，B2内容和A1内容的用户重合度=30%，那么可以看到B2内容对A1内容的承接能力更强。
  重合用户特征：用户人口统计学特征和用户行为特征，这个指标主要观测即将收官的内容是否能够承接用户给新热内容，如果新热内容不能完全承接则需要提取片库内的内容来留存用户。
  收入体系  GMV=DAU X 转化率 X ARPU GMV：gross merchandise volume，成交额 DAU：daily active user，日访问用户量 ARPU：average revenue per user，平均单用户收入 会员收入体系主要考量是否能够通过有效的售卖手段让用户续费和充值，广告收入体系主要考量分发是否准确，能够为广告主带来曝光和收益。  ROI策略 入水和出水 稳定的流量池——量和结构的稳定 流量池每天都会有入水和出水，我们不仅仅要关注量的稳定，还要关注结构的稳定，并且分析流入和流出的原因。
  量的稳定：需观测入水和出水的流转过程，通常关注DAU/WAU/MAU等能够反映用户总体活跃的指标，以及整体的拉新-留存-促活-承接体系是否周期性（有些指标在一定的时间周期内呈现规律性特征）运转健康正常，如果在某段时间中体系中某个指标出现异常（需要设定基准值），应该及时追溯原因并补救，一般头部内容可以反映大部分的整体情况，因此我们只需关注头部内容的特征指标即可。比如，某个头部内容在有比较高的资源投入上持续有较高新用户占比，但在某一集之后新用户占比和留存率都持续走低，那么有可能是以下几种原因：剧情出现问题 不再能够吸引用户/明星的吸引力有限 已不足以支持粉丝继续追剧/会员权益已释放 无持续的内容更新，如果判定由于权益不合理释放导致需调整排播策略和会员权益释放节奏，如果判定该内容已经不具备拉新和留存的能力则需将其做降级处理，以避免过多的资源投入浪费在不停的拉新和流失中。</description>
    </item>
    
    <item>
      <title>Regression：Linear Regression</title>
      <link>https://www.m1sty.com/2021/dm_regression_5_pracitise_linear-regression/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_regression_5_pracitise_linear-regression/</guid>
      <description>线性回归 一元线性回归 相关分析 一元线性回归模型  模型中的x称为自变量，y称为因变量; a为模型的截距项，b为模型的斜率项，ε为模型的误差项; 误差项ε的存在主要是为了平衡等号两边的值，通常被称为模型 无法解释的部分; 如果拟合线能够精确地捕捉到每一个点(即所有散点全部落在拟合线上)，那么对应的误差项ε应该为0; 所以，模型拟合的越好，则误差项ε应该越小。进而可以理解为: 求解参数的问题便是求解误差平方和最小的问题。  参数a和b求解  J(a,b)为目标函数，需求解该函数的最小值； 求解方法便是计算目标函数关于参数a和b的两个偏导数，最终令偏倒数为0即可。  模型的应用 # 导入第三方模块 import statsmodels.api as sm sm.ols(formula, data, subset=None, drop_cols=None)  formula:以字符串的形式指定线性回归模型的公式，如&amp;rsquo;y~x&amp;rsquo;就表示简单线性回归模型 data:指定建模的数据集 subset:通过bool类型的数组对象，获取data的子集用于建模 drop_cols:指定需要从data中删除的变量  # 导入第三方模块 import pandas as pd import statsmodels.api as sm # 导入数据 income = pd.read_csv(&amp;#39;Salary_Data.csv&amp;#39;) # 利用收入数据集，构建回归模型 fit = sm.formula.ols(&amp;#39;Salary ~ YearsExperience&amp;#39;, data = income).fit() # 返回模型的参数值 fit.params # 相关系数 income.columns income.Salary.corr(income.YearsExperience) 多元线性回归 定义  对于一元线性回归模型来说，其反映的是单个自变量对因变量的影响，然而实际情况中，影 响因变量的自变量往往不止一个，从而需要将一元线性回归模型扩展到多元线性回归模型。  参数求解 模型的应用  数据集包含5个变量，分别是产品的研发成本、管理成本、市场营销成本、销售市场和销 售利润。  # 导入模块 from sklearn import model_selection # 导入数据 Profit = pd.</description>
    </item>
    
    <item>
      <title>Interview outline</title>
      <link>https://www.m1sty.com/2021/overview_interview_map/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/overview_interview_map/</guid>
      <description>Database sql基础知识 sql基础知识
  索引：索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。根据数据库的功能，可以在数据库设计器中创建三种索引：唯一索引、主键索引和聚集索引。
 唯一索引：唯一索引是不允许其中任何两行具有相同索引值的索引。当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在employee表中职员的姓(lname)上创建了唯一索引，则任何两个员工都不能同姓。 主键索引：数据库表经常有一列或多列组合，其值唯一标识表中的每一行。该列称为表的主键。在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 聚集索引：在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。聚集索引和非聚集索引的区别，如字典默认按字母顺序排序，读者如知道某个字的读音可根据字母顺序快速定位。因此聚集索引和表的内容是在一起的。如读者需查询某个生僻字，则需按字典前面的索引，举例按偏旁进行定位，找到该字对应的页数，再打开对应页数找到该字。这种通过两个地方而查询到某个字的方式就如非聚集索引。    union all &amp;amp; union
 union和union all的区别是,union会自动压缩多个结果集合中的重复结果，而union all则将所有的结果全部显示出来，不管是不是重复。 *Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；*Union在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION。 *Union All：对两个结果集进行并集操作，包括重复行，不进行排序；*如果返回的两个结果集中有重复的数据，那么返回的结果集就会包含重复的数据了。    sql操作题 SQL面试必会50题
# 查询每门功成绩最好的前两名 SELECT c_id, max(case when rank1 = 1 then s_score else null end ) as &amp;#39;第一&amp;#39;, max(case when rank1 = 2 then s_score else null end ) as &amp;#39;第二&amp;#39; FROM (SELECT score.s_id, student.s_name, score.c_id, score.s_score, row_number() over(partition by c_id order by s_score DESC) rank1 FROM score INNER JOIN student ON score.</description>
    </item>
    
    <item>
      <title>Regression：Ridge Regression and Lasson Regression</title>
      <link>https://www.m1sty.com/2021/dm_regression_5_pracitise_ridge-regression-and-lasso-regression/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_regression_5_pracitise_ridge-regression-and-lasso-regression/</guid>
      <description>线性回归模型的短板 当列数比行数多 当列之间存在多重共线性 岭回归模型 为解决多元线性回归模型中可能存在的不可逆问题，统计学家提出了岭回归模型。该模型解决问题的思路就是在线性回归模型的目标函数之上增加l2正则项（也称为惩罚项）。
表达式 系数求解 凸优化的等价命题 系数求解的几何意义 交叉验证法 Lasso模型 岭回归模型解决线性回归模型中矩阵X&amp;rsquo;X不可逆的办法是添加l2正则的惩罚项,但缺陷在于始终保留建模时的所有变量,无法降低模型的复杂度。对于 此, Lasso回归采用了l1正则的惩罚项。
表达式 凸优化的等价命题 系数求解的几何意义 交叉验证法 实操 # 导入第三方模块 import pandas as pd import numpy as np from sklearn import model_selection from sklearn.linear_model import Ridge,RidgeCV import matplotlib.pyplot as plt # 读取糖尿病数据集 diabetes = pd.read_excel(r&amp;#39;diabetes.xlsx&amp;#39;) # 构造自变量（剔除患者性别、年龄和因变量） predictors = diabetes.columns[2:-1] # 将数据集拆分为训练集和测试集 X_train, X_test, y_train, y_test = model_selection.train_test_split(diabetes[predictors], diabetes[&amp;#39;Y&amp;#39;], test_size = 0.2, random_state = 1234 ) 多元线性回归 # 导入第三方模块 from statsmodels import api as sms # 为自变量X添加常数列1，用于拟合截距项 X_train2 = sms.</description>
    </item>
    
    <item>
      <title>Decistion Trees：Practise</title>
      <link>https://www.m1sty.com/2021/dm_decistion-trees_5_practise/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_decistion-trees_5_practise/</guid>
      <description>决策树与随机森林 决策树节点字段的选择和阈值的选择 决策树模型介绍  图中的决策树呈现自顶向下的生长过程，深色的椭圆表示树的根节点;浅色的椭圆表示树的中间节点;方框则表示树的叶节点。 对于所有的非叶节点来说，都是用来表示条件判断，而叶节点则存储最终的分类结果，例如中年分支下的叶节点(4,0)表示4位客户购买，0位客户不购买。  信息熵与条件熵  熵原本是物理学中的一个定义，后来香农将其引申到了信息论领域，用来表示信息量的大小。 信息量越大(分类越不“纯净”)，对应的熵值就越大，反之亦然。信息熵的计算公式如下:   在实际应用中，会将概率$P_k$的值用经验概率替换，所以经验信息熵可以表示为：   举例:以产品是否被购买为例，假设数据集一共包含14个样本，其中购买的用户有9个，没有购买 的用户有5个，所以对于是否购买这个事件来说，它的经验信息熵为:   条件熵  信息增益  信息增益：对于已知的事件A来说，事件D的信息增益就是D的信息熵与A事件下D的条件熵之差，事件A对于事件D的影响越大，条件熵H（D｜A）就会越小（在事件A的影响下，事件D就划分得越“纯净”），体现在信息增益熵就是差值越大，进而说明事件D的信息熵下降得越多。   所以，在根节点或中间节点的变量选择过程中，就是挑选出各自变量下因变量的信息增益最大的。  信息增益率  决策树中的ID3算法使用信息增益指标实现根节点或中间节点的字段选择，但是该指标存在一个非常明显的缺点，即信息增益会偏向于取值较多的字段。 为了克服信息增益指标的缺点，提出了信息增益率的概念，它的思想很简单，就是在信息增益的基础上进行相应的惩罚。信息增益率的公式可以表示为:   其中$H_A$为事件A的信息熵。事件A的取值越多$Gain_A$(D)可能越大，但同时$H_A$也会越大，这样以商的形式就实现了$Gain_A$(D)的惩罚。  基尼指数与条件基尼指数  决策树中的C4.5算法使用信息增益率指标实现根节点或中间节点的字段选择，但该算法与ID3算法一致，都只能针对离散型因变量进行分类，对于连续型的因变量就显得束手无策了。 为了能够让决策树预测连续型的因变量，Breiman等人在1984年提出了CART算法，该算法也称为分类回归树，它所使用的字段选择指标是基尼指数。   条件基尼指数  基尼指数增益  与信息增益类似，还需要考虑自变量对因变量的影响程度，即因变量的基尼指数下降速度的快慢，下降得越快，自变量对因变量的影响就越强。下降速度的快慢可用下方式子衡量:  生成算法与划分标准 随机森林的思想 分类树与回归树 分类树  以C4.5分类树为例，C4.5分类树在每次分枝时，是穷举每一个feature的每一个阈值，找到使得按照feature&amp;lt;=阈值，和feature&amp;gt;阈值分成的两个分枝的熵最大的阈值(熵最大的概念可理解成尽可能每个分枝的男女比例都远离1:1)，按照该标准分枝得到两个新节点，用同样方法继续分枝直到所有人都被分入性别唯一的叶子节点，或达到预设的终止条件，若最终叶子节点中的性别不唯一，则以多数人的性别作为该叶子节点的性别。 总结：分类树使用信息增益或增益比率来划分节点；每个节点样本的类别情况投票决定测试样本的类别。  回归树  回归树总体流程也是类似，区别在于，回归树的每个节点（不一定是叶子节点）都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差即(每个人的年龄-预测年龄)^2 的总和 / N。也就是被预测出错的人数越多，错的越离谱，均方差就越大，通过最小化均方差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄。 总结：回归树使用最大均方差划分节点；每个节点样本的均值作为测试样本的回归预测值  决策树模型函数说明 DecisionTreeClassifier(criterion=&amp;#39;gini&amp;#39;, splitter=&amp;#39;best&amp;#39;, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None, class_weight=None)  criterion:用于指定选择节点字段的评价指标，对于分类决策树，默认为&amp;rsquo;gini&#39;，表示采用基尼指数选择节点的最佳分割字段;对于回归决策树，默认为&amp;rsquo;mse&#39;，表示使用均方误差选择节点的最佳分割字段 splitter:用于指定节点中的分割点选择方法，默认为&amp;rsquo;best&#39;，表示从所有的分割点中选择最佳分割点; 如果指定为&amp;rsquo;random&#39;，则表示随机选择分割点 max_depth:用于指定决策树的最大深度，默认为None，表示树的生长过程中对深度不做任何限制 min_samples_split:用于指定根节点或中间节点能够继续分割的最小样本量，默认为2 min_samples_leaf:用于指定叶节点的最小样本量，默认为1 max_leaf_nodes:用于指定最大的叶节点个数，默认为None，表示对叶节点个数不做任何限制 class_weight:用于指定因变量中类别之间的权重，默认为None，表示每个类别的权重都相等;如果为balanced，则表示类别权重与原始样本中类别的比例成反比;还可以通过字典传递类别之间的权重差异，其形式为{class_label:weight}  随机森林模型介绍  利用Bootstrp抽样法，从原始数据集合中生成k个数据集，并且每个数据集都含有N个观测和P个自变量； 针对每一个数据集，构造一棵CART决策树，在构建子树的过程中，并没有将所有自变量用作节点字段的选择，而是随机选择p个字段； 让每一棵决策树尽可能地充分生长，使得树中的每个节点尽可能“纯净”，即随机森林中的每一棵子树都不需要剪枝； 针对k棵CART树的随机森林，对分类问题利用投票法，将最高得分的类别用于最终的判断结果；对回归问题利用均值法，将其用作预测样本的最终结果。  随机森林模型函数说明 RandomForestClassifier(n_estimators=10, criterion=&amp;#39;gini&amp;#39;, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_leaf_nodes=None, bootstrap=True, class_weight=None)  n_estimators:用于指定随机森林所包含的决策树个数 criterion:用于指定每棵决策树节点的分割字段所使用的度量标准，用于分类的随机森林，默认的 criterion值为&amp;rsquo;gini&#39;; 用于回归的随机森林，默认的criterion值为&amp;rsquo;mse&#39; max_depth:用于指定每棵决策树的最大深度，默认不限制树的生长深度 min_samples_split:用于指定每棵决策树根节点或中间节点能够继续分割的最小样本量，默认为2 min_samples_leaf:用于指定每棵决策树叶节点的最小样本量，默认为1 max_leaf_nodes:用于指定每棵决策树最大的叶节点个数，默认为None，表示对叶节点个数不做任 何限制 bootstrap:bool类型参数，是否对原始数据集进行bootstrap抽样，用于子树的构建，默认为True class_weight:用于指定因变量中类别之间的权重，默认为None，表示每个类别的权重都相等  代码实操 导入数据 # 导入第三方模块 import pandas as pd # 读入数据 Titanic = pd.</description>
    </item>
    
    <item>
      <title>Decistion Trees：Practise(project)</title>
      <link>https://www.m1sty.com/2021/dm_decistion-trees_6_practise_project/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_decistion-trees_6_practise_project/</guid>
      <description>随机森林模型项目代码 建模版 导入数据 import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import numpy as nps from scipy import stats from sklearn import metrics # 导入Excel文档 data=pd.read_excel(&amp;#39;D:\\Britney\\项目1\\K数据.xlsx&amp;#39;) 数据预处理 # 去除为0的行 a=data[data[&amp;#39;大货唛架 YY&amp;#39;]==0].index data1=data.drop(a,axis=0) data1[data1[&amp;#39;大货唛架 YY&amp;#39;].isin([0])] y1=data1[&amp;#39;大货唛架利用率%&amp;#39;] y2=data1[&amp;#39;大货唛架 YY&amp;#39;] #如果缺失率达到40%就可以去除该因子 d1=data1.isnull().sum()/data1.shape[0] #a=d1&amp;gt;0.5 a1=pd.DataFrame(d1) print(a1[a1[0]&amp;gt;0.4]) #去掉缺失率过大的因子 data2=data1.drop([&amp;#39;后整方式&amp;#39;,&amp;#39;循环尺寸标准_经向(Inch)&amp;#39;,&amp;#39;循环尺寸标准_纬向(Inch)&amp;#39;],axis=1) # 类型变量集合 quality=[attr for attr in data2.columns if data2.dtypes[attr] == &amp;#39;object&amp;#39;] # 类型变量缺失值补全 for c in quality: data2[c] = data2[c].</description>
    </item>
    
    <item>
      <title>Deep Learning and Neural Networks</title>
      <link>https://www.m1sty.com/2021/ed_6_deep-learning-and-neural-networks/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_6_deep-learning-and-neural-networks/</guid>
      <description>Deep Learning and Neural Networks Curriculum Structure  Read Chapter 7 and 8  Review of using scorecards for decision-making - Figure 1 and 2 Why use decision trees? What are neural networks and what are the benefits and risks of deep learning?   Amazon and the Alexa Voice Smart Speaker Breakthrough  Deep Learning and Image and Voice Recognition Breakthroughs Fastest Consumer Adoption in US History Internet of Things and the Connected Smart City   Summary  Class 6 PPT Deep Learning: Image &amp;amp; Voice Applied AI: Perform tasks with AI or apply AI to specific industry verticals  Virtual Assistance Generating Insights Automation of Manual Processes Unlocking Unstructured Data  AI “core” capabilities in Language &amp;amp; Vision NLP Natural Language Processing    https://www.</description>
    </item>
    
    <item>
      <title>Blue Ocean Strategy</title>
      <link>https://www.m1sty.com/2021/ed_5_midterm-review/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_5_midterm-review/</guid>
      <description>Blue Ocean Strategy Curriculum Structure  Industry Evolution from Emerging to Growth to Mature and Highly Competitive Blue Ocean Strategy: From Technology Innovation to Value Innovation Cirque du Soleil and YellowTail Wines Value Innovation cases Technology and Value Innovation in the Commuter Bicycle Industry  Class 5 PPT Industry Life Cycle &amp;amp; Porter&amp;rsquo;s Five Forces Stafes of the Industry Life Cycle Porter’s Five Forces Analysis of Industry Profitability Industry Life Cycle and Five Forces  Industries in the stages of Maturity and Decline will often seek government intervention or subsidies to help protect the declining industry.</description>
    </item>
    
    <item>
      <title>Machine Learning, InsurTech and Ethical Considerations</title>
      <link>https://www.m1sty.com/2021/ed_4_machine-learning-insurtech-and-ethical-considerations/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_4_machine-learning-insurtech-and-ethical-considerations/</guid>
      <description>Machine Learning, InsurTech and Ethical Considerations Curriculum Structure   How does Machine Learning work and why does data matter? Read Chapter 4 - 7
 Predicting heart attacks with a scorecard and common sense How much data do you need for Figure 2? What is the likelihood of Susan getting a heart attack in the next five years?    AI-enabled insurance: Improving the customer experience, better predictions and reduced claim fraud</description>
    </item>
    
    <item>
      <title>Competitive Advantage</title>
      <link>https://www.m1sty.com/2021/ed_3_competitive-advantage/</link>
      <pubDate>Sun, 21 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_3_competitive-advantage/</guid>
      <description>Competitive Advantage and Profitability Analysis Curriculum Structure   What is Competitive Advantage and how do you gain and sustain above-average profitability?
 Industry analysis vs firm-level analysis Calculating profit margins in low-cost, differentiated and dual advantage strategies Value chain analysis and profitability analysis Summary    How does this apply to the 3D Printed Carbon Fiber Bike Industry in the Venture Simulation Game?
 Trek and the Traditional Bike Producers Dragon and the Online Bike Startups Pricing, production and sales costs, market share and competitive advantage Summary    Class 3 PPT Competitive Advantage Defined Startegy Toolbox  Firm-level Analysis Industry-level Analysis  Competitive Advantage Analysis Value Chain Analysis    Level of Analysis: One Company vs.</description>
    </item>
    
    <item>
      <title>Applied AI in Business</title>
      <link>https://www.m1sty.com/2021/ed_2_applied-ai-in-business/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_2_applied-ai-in-business/</guid>
      <description>Applied AI in Business Curriculum Structure   Reading
 What is Machine Learning and the 5 components of AI systems（Read Chapter 1-3 of AI book）    Material
 Why use Machine Learning for Credit Scoring and deciding to give Loans? What are the 5 components of AI systems What are the 5 components of DoNotPay? Several FinTech Use Cases Summary Questions for reflection    Class 2 PPT Intro to Applied AI Four Pillars of Applied AI  Virtual Assistance Generating Insights Automation of Manual Processes Unlocking Unstructured Data  DoNotPay: Four Pillars of Applied AI?</description>
    </item>
    
    <item>
      <title>Intro Entrepreneurship Development</title>
      <link>https://www.m1sty.com/2021/ed_1_intro/</link>
      <pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/ed_1_intro/</guid>
      <description>Topic Topics covered
 The Business Model Canvas Customer Discovery Value Propositions &amp;amp; Minimal Viable Products Channels and Influencers Pivots Revenues and Pricing Models Resources, Activities and Partners Costs, Metrics, Financials and Fundraising Crowdfunding, Venture Capital Hong Kong incubators and accelerators Applied AI in Business The Applied AI Data Business Model Canvas The AI Startup Playbook  MVP Minimum Viable Product
Business Model Canvas Steve Blank Lean Startup Videos Value Proposition Videos</description>
    </item>
    
    <item>
      <title>PageRank：Content(1)</title>
      <link>https://www.m1sty.com/2021/dm_pagerank_1_content1/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_pagerank_1_content1/</guid>
      <description>Data and Algorithms of the Web Link Analysis Algorithms &amp;amp; Page Rank Link Analysis Algorithms  Page Rank Hubs and Authorities Topic-Specific Page Rank Spam Detection Algorithms Other interesting topics we won&amp;rsquo;t cover  Detecting duplicates and mirrors Mining for communities    Ranking Web Pages  Web pages are not equally “important” www.bernard.com and www.stanford.edu both contain both the term “stanford” but:  www.stanford.edu has 23,400 webpages linking to it www.</description>
    </item>
    
    <item>
      <title>Top-k Query：Content</title>
      <link>https://www.m1sty.com/2021/atdm_top-k_1_content/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_top-k_1_content/</guid>
      <description>Top-k Queries Background Multidimensional Data  Flat relational tables Multimedia feature vectors Data warehouse data Spatial data Text documents  Attribute Types  Attributes of multidimensional tuples may have variable types  Ordinal (e.g., age, salary) Nominal categorical values (e.g., color, religion) Binary (e.g., gender, owns_property)   Basic queries: range, NN, similarity  Basic Queries  (Range) selection query  Returns the records that qualify a (multidimensional) range predicate Example:  Return the employees of age between 45 and 50 and salary above $100,000     Distance (similarity) query  Returns the records that are within a distance from a reference record.</description>
    </item>
    
    <item>
      <title>PageRank：Content(2)【Not finish】</title>
      <link>https://www.m1sty.com/2021/dm_pagerank_1_content2/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_pagerank_1_content2/</guid>
      <description>The Theory behind PageRank Computing Importance  Web graph: a directed graph G = (V , E ) where nodes represent web pages, while there is a directed edge between u and v if there is a hyperlink between the corresponding web pages. Importance of v is proportional to the importance of nodes linking to v. It can be modeled by a system of linear equations&amp;hellip;  System of Linear Equations for PageRank PageRank  The importance of a web page can be computed by solving the corresponding system of linear equations.</description>
    </item>
    
    <item>
      <title>Top-k Query：Tutorial</title>
      <link>https://www.m1sty.com/2021/atdm_top-k_2_tutorial/</link>
      <pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_top-k_2_tutorial/</guid>
      <description>TA &amp;amp; NRA Qustion A website posts information about apartments. Suppose that there are 10 apartments to be sold, together with their ratings($a_1$) and prices($a_2$), as listed in the table below. The website employs an aggregation function f = 0.6*$a_1$+ 0.4*$a_2$ to rank these apartments.
Q1) Write down two lists of apartments, in descending order of $a_1$ and $a_2$.
Q2) Use the TA algorithm to find the two best apartments in terms of f.</description>
    </item>
    
    <item>
      <title>PageRank：Exercise</title>
      <link>https://www.m1sty.com/2021/dm_pagerank_2_exercise/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_pagerank_2_exercise/</guid>
      <description>Simple Wev Graph and its Matrix System of Linear Equations PageRank Algorithm </description>
    </item>
    
    <item>
      <title>Artificial Intelligence and Machine Learning for Business</title>
      <link>https://www.m1sty.com/2021/business_book_artificial-intelligence-and-machine-learning-for-business/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/business_book_artificial-intelligence-and-machine-learning-for-business/</guid>
      <description>Artificial Intelligence and Machine Learning for Business 1.Introduction Topics in the book  What machine learning and artificial intelligence are. The sort o things organizations use artificial intelligence for. What a predictive model looks like. The relationship between artificial intelligence, machine learning and Big Data. The people and tools needed to apply artificial intelligence. How to use artificial intelligence to improve business processes and the bottom line. The legal and ethical issues that need to be considered when developing artificial intelligence based solutions that are going to be used to make decisions about people.</description>
    </item>
    
    <item>
      <title>Top-k Query：Supplement</title>
      <link>https://www.m1sty.com/2021/atdm_top-k_4_more/</link>
      <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_top-k_4_more/</guid>
      <description>Threshold Algorithm (TA)  Original version, often used as synonym for entire family of top-k algorithms. But: eager random access to candidate objects required. Worst-case memory consumption is strictly bounded → O(k)  No-Random-Access Algorithm (NRA)  No random access required at all, but may have to scan large parts of the index lists. Worst-case memory consumption bounded by index size → O(m*n + k)  </description>
    </item>
    
    <item>
      <title>PageRank：Supplement</title>
      <link>https://www.m1sty.com/2021/dm_pagerank_4_more/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_pagerank_4_more/</guid>
      <description>Key words  Link Analysis PageRank  Links 海量数据挖掘MMDS week1: Link Analysis - PageRank
链接分析（Link Analysis）：PageRank算法</description>
    </item>
    
    <item>
      <title>Tableau学习心得与模板分享</title>
      <link>https://www.m1sty.com/2021/visualization_tableau_map/</link>
      <pubDate>Sat, 06 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/visualization_tableau_map/</guid>
      <description>学习路径 Tableau 入门套件 简单了解Tableau的界面和基础操作。
https://www.tableau.com/zh-cn/learn/starter-kits
建议学习时间：两天
Tableau eLearning 分为基础、中级、高级，每一个专题都设置了练习题，根据指引完成练习题。
https://www.tableau.com/zh-cn/learn/training/elearning
ps：不建议在B站只看视频版，因为实际动手操作（练习题模块）是Tableau学习的关键。
建议学习时间：一周
Tableau Public 优秀模版积累，学习仪表板设计方式与页面逻辑。
https://public.tableau.com/zh-cn/s/
建议学习时间：长期积累
Tableau 白皮书 阅读有关数据可视化和 Tableau 最佳做法的深度信息。
https://www.tableau.com/zh-cn/learn/whitepapers
 推荐模板 Must Read Books By Black Authors 马克，以后可以用来做学习路径图谱
https://public.tableau.com/zh-cn/gallery/must-read-books-black-authors?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
Analyzing the Work of Bob Ross 可以用于关联规则分析的可视化展现
https://public.tableau.com/zh-cn/gallery/analyzing-work-bob-ross?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
Disney+ 交互设计非常有趣，可以用于运营数据展现
https://public.tableau.com/zh-cn/gallery/disney?tab=viz-of-the-day&amp;amp;type=viz-of-the-day
PPP Loan Data 适用年终汇报
https://public.tableau.com/profile/dzifa.amexo#!/vizhome/PPPLoanData-MAD4Week7/Overview
Website Traffic Analysis 网站流量数据仪表板
https://public.tableau.com/profile/allison.wright4813#!/vizhome/WebsiteTrafficAnalysis_16032478866130/Webalytics-AnalyticsPackage
 结语 Tableau将原始数据转变为可操作、集成化、有意义的仪表板，有利于发现数据规律、找到数据问题、制定解决方案。
Tableau的学习最重要的就是动手操作，学习数据的逻辑、页面的布局，如何在有限的版面聚合更多的有效信息。而页面的美观只是其次的。</description>
    </item>
    
    <item>
      <title>Clusterings：Content</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_1_content/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_1_content/</guid>
      <description>Clusterings Background What is Cluster Analysis  Finding groups of objects such that the objects in a group will be similar (or related) to one another and different from (or unrelated to) the objects in other groups  Intra-cluster distances are minimized Inter-cluster distances are maximized   Notion of a Cluster can be Ambiguous  Applications of Cluster Analysis  Understanding  Group related documents for browsing, group genes and proteins that hav similar functionality, or group stocks with similar price fluctuations   Summarization  Reduce size of large data sets    What is not Cluster Analysis  Superviesd classification  Have class label information   Simple segmentation  Dividing students into different registration groups alpgabetically, by last name   Results of a query  Groupings are a result of an external specification   Graph partitioning  Some mutual relevance and synergy, but areas are not identical    Types of Clusterings Introduction   A clustering is a set of clusters</description>
    </item>
    
    <item>
      <title>Spatial Networks：Content</title>
      <link>https://www.m1sty.com/2021/atdm_spatial-networks_1_content/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_spatial-networks_1_content/</guid>
      <description>Spatial Networks Background Network Distance  In many real applications accessibility of objects is restricted by a spatial network  Examples  Driver looking for nearest gas station Mobile user looking for nearest restaurant     Shortest path distance used instead of Euclidean distance SP(a,b) = path between a and b with the minimum accumulated length  Challenges  Euclidean distance is no longer relevant  R-tree may not be useful, when search is based on shortest path distance   Graph cannot be flattened to a one-dimensional space  Special storage and indexing techniques for graphs are required   Graph properties may vary  directed vs.</description>
    </item>
    
    <item>
      <title>Clusterings：Exercise</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_2_exercise/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_2_exercise/</guid>
      <description>Clusterings K-Means Algorithm Input Points Centroids Reclustering step 1 Recomputing centroids step 2 Recomputing the centroids step 3 Final Clustering K-Means++: Main Intuition Probaility distribution Sampling points Examples K-means- To understand why K-means++ use some randomness we compare it against the following algorithm which we call it K-means–:
The algorithm selects the first point randomly. Let t be any step of the algorithm, with 2 ≤ t &amp;lt; k. Let C be the set of points chosen at step t.</description>
    </item>
    
    <item>
      <title>Spatial Networks：Tutorial</title>
      <link>https://www.m1sty.com/2021/atdm_spatial-networks_2_tutorial/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_spatial-networks_2_tutorial/</guid>
      <description>Dijkstra&amp;rsquo;s algorithm review A* search algorithm review Nearest neighbor search exercise Question Consider a spatial network database, which includes a road network graph G and a set of points of interest P. The points in P can only be located on the vertices or edges of G. Each point of interest is with some labels (at least one), e.g., &amp;lsquo;school&amp;rsquo;, &amp;lsquo;hotel&amp;rsquo;, &amp;lsquo;restaurant&amp;rsquo;. The points P are indexed by an R-tree $R_P$ based on location and by an inverted file (see the demo below) IP based on the labels.</description>
    </item>
    
    <item>
      <title>Clusterings：Assignment</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_3_assignment/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_3_assignment/</guid>
      <description>Clusterings Theoretical exercises on K-means Qustion 1 Answer 1 Input Points and Set Centroids Input P1=(0,0), P2=(0,1/2), P3=(1,1/2), P4=(1,1), P5=(4,0), P6=(4,1), P7=(5,1)
Set P1=(0,0) and P4=(1,1) as centroids
Reclustering  STEP 1  For each point P2, P3, P5, P6, P7, determine the closest centroid
   d(a,P1) distance d(a,P4) distance     d(P2,P1) $\sqrt{ 0^2 + (\frac{1}{2})^2 }$ d(p2,p4) $\sqrt{ (\frac{1}{2})^2 + 1^2 }$   d(P3,P1) $\sqrt{ (\frac{1}{2})^2 + 1^2 }$ d(P3,P4) $\sqrt{ 0^2 + (\frac{1}{2})^2 }$   d(P5,P1) $\sqrt{ 0^2 + 4^2 }$ d(P5,P4) $\sqrt{ 1^2 + 3^2 }$   d(P6,P1) $\sqrt{ 1^2 + 4^2 }$ d(P6,P4) $\sqrt{ 0^2 + 3^2 }$   d(P7,P1) $\sqrt{ 1^2 + 5^2 }$ d(P7,P4) $\sqrt{ 0^2 + 4^2 }$    P2 is assigned to the red cluster</description>
    </item>
    
    <item>
      <title>Clusterings：Supplement</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_4_more/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_4_more/</guid>
      <description>Clusterings 《数据挖掘概念与技术》 第10章小结  簇是数据对象的集合,同一个簇中的对象彼此相似,而不同簇中的对象彼此相异。将物理或抽象对象的集合划分为相似对象的类的过程称为聚类。 聚类分析具有广泛的应用,包括商务智能、图像模式识别、Web搜索、生物学和安全。聚类分析可以作为独立的数据挖掘工具来获得对数据分布的了解,也可以作为在检测的簇上运行的其他数据挖掘算法的预处理步骤。 聚类是数据挖掘研究一个富有活力的领域。它与机器学习的无监督学习有关。 聚类是一个充满挑战的领域,其典型的要求包括可伸缩性、处理不同类型的数据和属性的能力、发现任意形状的簇、确定输入参数的最小领域知识需求、处理噪声数据的能力、增量聚类和对输入次 序的不敏感性、聚类高维数据的能力、基于约束的聚类,以及聚类的可解释性和可用性。 已经开发了许多聚类算法,这些算法可以从多方面分类,如根据划分标准、簇的分离性、所使用的相似性度量和聚类空间。本章讨论如下几类主要的基本聚类方法:划分方法、层次方法、基于密度的方法和基于网格的方法。有些算法可能属于多个类别。 划分方法首先创建k个分区的初始集合,其中参数k是要构建的分区数。然后,它采用选代重定位技术,试图通过把对象从一个簇移到另一个簇来改进划分的质量。典型的划分方法包括k-均值、k-中心点、 CLARANS。 层次方法创建给定数据对象集的层次分解。根据层次分解的形成方式,层次方法可以分为凝聚的 (自底向上)或分裂的(自顶向下)。为了弥补合并或分裂的僵硬性,凝聚的层次方法的聚类质量可以通过以下方法改进:分析每个层次划分中的对象连接(如Chameleon),或者首先执行微聚类(也就是把数据划分为“微簇”),然后使用其他的聚类技术,迭代重定位,在微簇上聚类(如BIRCH)。 基于密度的方法基于密度的概念来聚类对象。它或者根据邻域中对象的密度(例如DBSCAN),或者根据某种密度函数(例如DENCLUE)来生成簇。OPTICS是一个基于密度的方法,它生成数据聚类结构的一个增广序。 基于网格的方法首先将对象空间量化为有限数目的单元,形成网格结构,然后在网格结构上进行聚类。STNG是基于网格方法的一个典型例子,它基于存储在网格单元中的统计信息聚类。CLIQUE是基于网格的子空间聚类算法。 聚类评估估计在数据集上进行聚类分析的可行性和由聚类方法产生的结果的质量。任务包括评估聚类趋势、确定簇数和测定聚类的质量。  第11章小结  在传统的聚类分析中,对象被互斥地指派到一个簇中。然而,在许多应用中,需要以模糊或概率方式把一个对象指派到一个或多个簇。模糊聚类和基于概率模型的聚类允许一个对象属于一个或多个 簇。划分矩阵记录对象属于簇的隶属度。 基于概率模型的聚类假定每个簇是一个有参分布。使用待聚类的数据作为观测样本,我们可以估计簇的参数 混合模型假定观测对象是来自多个概率簇的实例的混合。从概念上讲,每个观测对象都是通过如下方法独立地产生的:首先根据簇概率选择一个概率簇,然后根据选定簇的概率密度函数选择一个样本。 期望最大化(EM)算法是一个框架,它通近最大似然或统计模型参数的后验概率估计。EM算法 可以用来计算模糊聚类和基于概率模型的聚类。 高维数据对聚类分析提出了一些挑战,包括如何对高维簇建模和如何搜索这样的簇。 高维数据聚类方法主要有两类:子空间聚类方法和维归约方法。子空间聚类方法在原空间的子空间中搜索簇。例子包括子空间搜索方法、基于相关性的聚类方法和双聚类方法。维归约方法创建较低维的新空间,并在新空间搜索簇。 双聚类方法同时聚类对象和属性。双簇的类型包括具有常数值、行/列常数值、相干值、行/列相干 演变值的双簇。双聚类方法的两种主要类型是基于最优化的方法和枚举方法。 谱聚类是一种维归约方法。其一般思想是使用相似矩阵构建新维。 聚类图和网络数据有许多应用,如社会网络分析。挑战包括如何度量图中对象之间的相似性和如何为图和网络数据设计聚类方法。 测地距是图中两个顶点之间的边数,它可以用来度量相似性。另外,像社会网络这样的图的相似性也可以用结构情境和随机游走度量。SimRank是一种基于结构情境和随机游走的相似性度量。 图聚类可以建模为计算图割。最稀疏的割导致好的聚类,而模块性可以用来度量聚类质量。 SCAN是一种图聚类算法,它搜索图,识别良连通的成分作为簇。 约束可以用来表达具体应用对聚类分析的要求或背景知识。聚类约束可以分为实例、簇和相似性度量上的约束。实例上的约束可以是必须联系约束和不能联系约束。约束可以是硬性的或软性的。 聚类的硬性约束可以通过在聚类指派过程严格遵守约束而强制实施。软性约束聚类可以看做一个优化问题。可以使用启发式方法加快约束聚类的速度。  </description>
    </item>
    
    <item>
      <title>Spatial Networks：Supplement</title>
      <link>https://www.m1sty.com/2021/atdm_spatial-networks_4_more/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/atdm_spatial-networks_4_more/</guid>
      <description>Shortest Path Search Dijkstra&amp;rsquo;s algorithm   Dijkstra算法用来寻找图形中节点之间的最短路径。
  在Dijkstra算法中，需要计算每一个节点距离起点的总移动代价。同时，还需要一个优先队列结构。对于所有待遍历的节点，放入优先队列中会按照代价进行排序。
  在算法运行的过程中，每次都从优先队列中选出代价最小的作为下一个遍历的节点。直到到达终点为止。
  A* algorithm   A*算法通过下面这个函数来计算每个节点的优先级:
 f(n)=g(n)+h(n)  f(n)是节点n的综合优先级。当我们选择下一个要遍历的节点时，我们总会选取综合优先级最高（值最小）的节点。 g(n) 是节点n距离起点的代价。 h(n)是节点n距离终点的预计代价，这也就是A*算法的启发函数。      A*算法在运算过程中，每次从优先队列中选取f(n)值最小（优先级最高）的节点作为下一个待遍历的节点。
  另外，A*算法使用两个集合来表示待遍历的节点，与已经遍历过的节点，这通常称之为open_set和close_set。
   在极端情况下，当启发函数h(n)始终为0，则将由g(n)决定节点的优先级，此时算法就退化成了Dijkstra算法。 如果h(n)始终小于等于节点n到终点的代价，则A*算法保证一定能够找到最短路径。但是当h(n)的值越小，算法将遍历越多的节点，也就导致算法越慢。 如果h(n)完全等于节点n到终点的代价，则A*算法将找到最佳路径，并且速度很快。可惜的是，并非所有场景下都能做到这一点。因为在没有达到终点之前，我们很难确切算出距离终点还有多远。 如果h(n)的值比节点n到终点的代价要大，则A*算法不能保证找到最短路径，不过此时会很快。 在另外一个极端情况下，如果h(n)相较于g(n)大很多，则此时只有h(n)产生效果，这也就变成了最佳优先搜索。  Bi-directional search Spatial queries over spatial networks  Data:  A (static) spatial network (e.g., city map) A (dynamic) set of spatial objects   Spatial queries based on network distance:  Selections.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(K-means)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</guid>
      <description>Clusterings K-means聚类的思想和原理 模型介绍 对于监督的数据挖掘算法而言，数据集中需要包含标签变量（即因变量y的值）。但在有些场景下，并没有给定的y值，对于这类数据的建模，一般称为无监督的数据挖掘算法，最典型的当属聚类算法。
K-means聚类算法利用距离远近的思想将目标数据为制定的k个簇，进而使样本呈现簇内差异小，簇间差异大的特征。
聚类步骤  从数据中随机挑选k个样本点作为原始的簇中心 计算剩余样本与簇中心的距离，并把各样本标记为离k个簇中心最近的类别 重新计算各簇中样本点的均值，并以均值作为新的k个簇中心 不断重复第二步和第三步，直到簇中心的变化趋于稳定，形成最终的k个簇  原理介绍 最佳K值的选择 拐点法 簇内离差平方和拐点法的思想很简单，就是在不同的k值下计算簇内利差平方和，然后通过可视化的方法找到“拐点”所对应的k值。当折线图中的斜率由大突然变小时，并且之后的斜率变化缓慢，则认为突然变化的点就是寻找的目标点，因为继续随着簇数k的增加，聚类效果不再有大的变化。
def k_SSE(X,cluster): # 选择连续的K种不同的值 K = range(1,clusters+1) # 构建空列表用于存储总的簇内离差平方和 TSSE = [] for k in K: # 用于存储各个簇内离差平方和 SSE = [] kmeans = KMeans(n_clusters = k) Kmeans.fit(X) # 返回簇标签 labels = Kmeans.labels_ # 返回簇中心 centers = Kmeans.cluster_centers_ # 计算各簇样本的离差平方和，并保存到列表中 for label in set(labels): SEE.append(np.sum((X.loc[labels == label,]-centers[label,:])**2)) # 计算总的簇内离差平方和 TSSE.append(np.sum(SSE)) 轮廓系数法 该方法综合考虑了簇的密集性和分散性两个信息，如果数据集被分割为理想的k各簇，那么对应的簇内样本会很密集，而簇间样本会很分散，轮廓系数的计算公式可以表示为：
其中，a(i)体现了簇内的密集性，代表样本i与同簇内其他样本点距离的平均值；b(i)反映了簇间的分散性，它的计算过程是，样本i与其他非同簇样本点距离的平均值，然后从平均值中挑选出最小值。
当S(i)接近于-1时，说明样本i分配的不合理，需要将分配到其他簇中；当S(i)近似为0时，说明样本i落在了模糊地带，即簇的边界处；当S(i)近似为1时，说明样本i的分配是合理的。
# 构造自定义函数 def k_silhouette(X,clusters): K = range(2,clusters+1) # 构建空列表，用于存储不同簇数下的轮廓系数 S = [] for k in K: kmeans = KMeans(n_clusters = k) Kmenas.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(DBSCAN)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</guid>
      <description>Clusterings 熟悉密度聚类中的几个概念 模型介绍   Kmeans聚类存在两个致命缺点，一是聚类效果容易受到异常样本点的影响;二是该算法无法准确地将非球形样本进行合理的聚类。
  基于密度的聚类则可以解决非球形簇的问题，“密度”可以理解为样本点的紧密程度，如果在指定的半径领域内，实际样本量超过给定的最小样本量阈值，则认为是密度高的对象，就可以聚成一个簇。
  概念讲解  点的领域：在某点p处，给定其半径e后，所得到的覆盖区域 核心对象：对于给定的最少样本量MinPts而言，如果某点p的e领域内至少包含MinPts个样本点，则点p就为核心对象。 直接密度可达：假设点p为核心对象，且在点p的e领域内存在点q，则从点p出发到点q是直接密度可达的。 密度可达：假设存在一系列的对象链$P_1$,$P_2$,&amp;hellip;,$P_n$，如果$p_i$是关于半径e和最少样本点MinPts的直接密度可达$P_(i+1)$，则p1密度可达$P_n$。(i = 1,2,&amp;hellip;n) 密度相连：假设点o为核心对象，从点o出发得到两个密度可达点p和点q，则称点p和点q是密度相连的。 聚类的簇：簇包含了最大的密度相连所构成的样本点。 边界点：假设点p为核心对象，在其领域内包含了点b，如果点b为非核心对象，则称其为点p的边界点。 异常点：不属于任何簇的样本点。  理解密度聚类的过程 步骤讲解  为密度聚类算法设置一个合理的半径以及半径领域内所包含的最少样本量MinPts。 从数据集中随机挑选一个样本点p，检验其在半径领域内是否包含制定的最少样本量，如果包含就将其定性为核心对象，并构成一个簇C；否则，重新挑选一个样本点。 对于核心对象p所覆盖的其他样本点q，如果点q对应的半径领域内仍然包含最少样本量MinPts，就将其覆盖的样本点统统归于簇C。 重复步骤（3），将最大的密度相连所包含的样本点聚为一类，形成一个大簇。 完成步骤（4）后，重新回到步骤（2），并重复步骤（3）和（4），直到没有新的样本点可以生成新簇时算法结束。  函数介绍 cluster.DBSCAN(eps=0.5, min_samples=5, metric=‘euclidean’, p=None)   eps:用于设置密度聚类中的e领域，即半径，默认为0.5。
  min_samples:用于设置e领域内最少的样本量，默认为5。
  metric:用于指定计算点之间距离的方法，默认为欧氏距离 。
  p:当参数metric为闵可夫斯基(&amp;lsquo;minkowski&amp;rsquo;)距离时，p=1，表示计算点之间的曼哈顿距离;p=2，表示计算点之间的欧式距离；该参数的默认值为2。
  密度聚类相比Kmeans聚类的优势 球形簇的情况 K-means DBSCAN 非球形簇的情况 K-means DBSCAN DBSCAN难确定半径和MinPts
密度聚类的应用实战 利用自定义球形簇数据对比DBSCAN和K-means # 导入第三方模块 import pandas as pd import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(Hierarchical Clusterings)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</guid>
      <description>层次聚类 理论说明 https://blog.csdn.net/shulianghan/article/details/105960850
https://blog.csdn.net/liujh845633242/article/details/103679724
层次聚类更适合小样本；K-Means更适合大样本。
代码实现 # 导入第三方模块 import pandas as pd import numpy as np from sklearn.datasets import make_blobs import matplotlib.pyplot as plt import seaborn as sns from sklearn import cluster # 构造两个球形簇的数据样本点 X,y = make_blobs(n_samples = 2000, centers = [[-1,0],[1,0.5]], cluster_std = [0.2,0.45], random_state = 1234) # 将模拟得到的数组转换为数据框，用于绘图 plot_data = pd.DataFrame(np.column_stack((X,y)), columns = [&amp;#39;x1&amp;#39;,&amp;#39;x2&amp;#39;,&amp;#39;y&amp;#39;]) # 绘制散点图（用不同的形状代表不同的簇） sns.lmplot(&amp;#39;x1&amp;#39;, &amp;#39;x2&amp;#39;, data = plot_data, hue = &amp;#39;y&amp;#39;,markers = [&amp;#39;^&amp;#39;,&amp;#39;o&amp;#39;], fit_reg = False, legend = False) # 显示图形 plt.</description>
    </item>
    
    <item>
      <title>Association：Content(1)</title>
      <link>https://www.m1sty.com/2021/dm_association_1_content1/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_1_content1/</guid>
      <description>Frequent Itemsets and Association Rules Market Baskets The Market-Basket Model   A large set of items, e.g., things sold in a supermarket.
  A large set of baskets, each of which is a small set of the items, e.g., the things one customer buys on one day.
  A general many-many mapping (association) between two kinds of things.
  The technology focuses on common events, not rare events (“long tail”).</description>
    </item>
    
    <item>
      <title>Association：Content(2)</title>
      <link>https://www.m1sty.com/2021/dm_association_1_content2/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_1_content2/</guid>
      <description>Improvements to A-Priori PCY Algorithm Introdution  Main observation: during pass 1 of A-priori, most memory is idle. Use that memory to keep additional info to improve storage during pass 2 of A-priori. Passes &amp;gt; 2 are the same as in A-Priori.  Pass 1  Use a hash function which &amp;ldquo;bucketizes&amp;rdquo; item pairs, that is, maps them to integers in $[1,k]$. Each &amp;ldquo;bucket&amp;rdquo; i in $[1,k]$ is associated with a counter $c_i$.</description>
    </item>
    
    <item>
      <title>搭建数据指标体系</title>
      <link>https://www.m1sty.com/2021/project_data-index_content/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/project_data-index_content/</guid>
      <description>数据指标体系搭建 前言 2019年-2020年，我在服装制造业公司担任数据分析项目专员，为公司生产项目提供统计分析、数据挖掘与建模、数据可视化、数据库优化的技术支持。作为一个本科有互联网背景的新人，经常被公司的前辈问到两个问题，是否会觉得实体产业的数据分析太过于枯燥（互联网的数据分析和实体产业的数据分析有什么区别），如何将互联网的数据分析思想应用到实体产业的数据分析中（数据化时代的制造业转型）。
关于第一个问题，不可否认实体产业的数据分析是枯燥的，但是对提升数据敏感度、数据处理能力和建模水平是很有帮助的。不像用户画像分析、市场分析这样可以输出有趣的规则与结果，实体产业的数据分析的结果只是一堆数字（结果），永远在调参和在调参的路上，时不时还会被生产的同事怼这个结果不符合生产经验。我在参加公司的第一个月几乎每天都要去车间研究衬衫的制作过程。但是正是因为不断对这种“不显著”、“不知含义”的数据的探究，磨练了我的数据处理能力和建模水平，对于梭织，我处理了十万条生产数据、将参与分析的近百个因子缩减到30个，对于针织，我的建模准确率已经达到可投入使用、嵌入报价系统的标准。
关于第二个问题，也就是互联网的数据分析思想如何应用到实体产业中。这个问题太大了，我作为一个萌新，要回答这个问题多少有些不知深浅。在这篇文章里想要分享的就是数据指标体系搭建，我认为这是一个非常综合的体现数据分析能力和思想的工作。数据指标体系搭建是建立数字产品、提供数字服务的前提条件之一，最终的目的是实现互联网行业（或者说是制造业）的企业数字生态化。
本篇文章是对数据指标体系搭建的学习笔记和案例应用（以互联网行业为主，增加一些制造业数据分析的心得），最后注明学习资料来源。
数据指标体系的概念 定义 指标体系是将零散单点的具有相互联系的指标，系统化的组织起来，通过单点看全局，通过全局解决单点的问题。它主要由指标和体系两部分组成。
指标是指将业务单元细分后量化的度量值，它使得业务目标可描述、可度量、可拆解，它是业务和数据的结合，是统计的基础，也是量化效果的重要依据。
  结果型指标：用于衡量用户发生某个动作后所产生的结果，通常是延后知道的，很难进行干预。结果型指标更多的是监控数据异常，或者是监控某个场景下用户需求是否被满足。
  过程型指标：用户在做某个动作时候所产生的指标，可以通过某些运营策略来影响这个过程指标，从而影响最终的结果，过程型指标更加关注用户的需求为什么被满足或没被满足。
  指标体系生命周期 生命周期主要包含定义、生产、消费、下线四个阶段。针对整个生命周期要持续做指标运维、质量保障，同时为了提高指标数据复用度，降低用户使用成本需要做对应的数据运营工作。
应用场景 指标体系主要是结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题。常用的场景一种是决策分析的场景，通过数据看清业务现状进行战略决策支持，另一种是运营分析场景，无论是做用户运营、产品运营还是活动运营都需要各类指标数据的支撑去看清问题、分析问题和指导解决问题。
为什么要搭建数据指标体系？ 横向意义  衡量业务发展质量：指标体系可以反映业务客观事实，看清业务发展现状，通过指标对业务质量进行衡量，把控业务发展情况，针对发现的业务问题聚焦解决，促进业务有序增长。 建立指标因果关系：主要明确结果型指标和过程型指标关系，通过结果指标回溯过程指标，找到解决问题的核心原因。 指导用户分析工作：目的建立产品评估体系、活动效果评估体系、智能运营分析体系。 指导基础数据建设：明确基础数据建设方向，集中资源，避免过程和结果分析指标数据的遗漏或缺失。 指导内容产品建设：结合用户的业务场景来进行使用，多个不同的指标和维度可以组合起来进行业务的综合分析，用户可通过指标的变化看到整体业务的变化，并能够快速发现问题、定位问题。 统一指标消费口径：企业内统一关键指标业务口径及计算口径，统一企业业务目标，实现自上而下目标驱动。  纵向意义  业务规整 数据管理、数据仓库 数字产品、数字服务 企业数字生态化、数字驱动  数据指标体系搭建流程 STEP1：数据指标选取 快速了解行业/企业/业务 拆解业务模块  内容：  了解产品形态：指的是熟悉整个产品的运作逻辑，关注的是用户角色，信息和渠道，以及他们之间的流转关系是什么样的，也就是产品的框架； 了解业务逻辑：指的是要执行某个业务，用户角色需要走过的路径，会有什么角色参与，有什么功能模块（或子系统），模块之间的关联性，数据之间的流向是什么样的； 绘制业务流程图：在了解了业务逻辑的基础上，把功能分解下来，划分具体的细节流程，异常流程或提示等【业务流程图、数据流程图、visio的使用】。   方法：  用户行为法：数据分析的最终落脚点都会落到用户的行为分析上，只有更好地了解用户习惯、用户偏好、用户画像才能更好地创新或改进或迭代产品。用户行为法是将自己带入到产品与业务中去，实际的走一遍产品流程与业务流程，了解我们在这个过程中所收获的一些信息。 业务拆分法：业务拆分法针对的对象是一些大型的生态型企业，他们的业务多种多样，每个业务板块的产品布局也是不相同的。把业务拆分成不同的子模块，既可以通过优势互补来达到共享资源，也可以将每个子业务经过重新定位来强化营收，同时业务之间增加其竞争力，在强化业务中寻求大创新与大突破。 指标推进法：指标推进法其实就是将企业的总指标进行层层划分，可以按照流程或者公式来进行拆解，根据分解的指标所涉及的工作内容，来了解整体业务的详细流程。 商业画布：商业画布是一种分析企业价值的工具，通过把商业模式中的元素标准化，引导我们的思维，将业务知识素材归档。    例子  电商类产品  商品类指标 营销类指标 风控类指标 市场竞争类指标 电商总体运营类指标 流量类指标 销售转化类指标 客户价值指标   o2o类产品  流量类指标 订单相关指标 登陆注册指标 生命周期相关指标 行为转化指标 用户属性指标    梳理业务与指标 鱼骨图/逻辑树/MECE原则 对业务流程图、数据流程图进行进一步分析，把复杂的业务问题拆解成多个简单问题，进而拆分更细的数据指标，有利于把握核心指标，提升指标系统的有效性。</description>
    </item>
    
    <item>
      <title>Association：Exercise</title>
      <link>https://www.m1sty.com/2021/dm_association_2_exercise/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_2_exercise/</guid>
      <description>Naive Algorithm Pass 1 Support treshold：2
Pass 2 Support treshold：2
Pass 3 Support treshold：2
A-priori Algorithm Pass 1 Pass 2 Pass 3 PCY Algorithm Input Data Pass 1 Pass 2 The remaining passes The remaining passes are the same of A-priori
SON Algorithm Introduction Let s be the support threshold:
 Pass 1:  Divide the dataset into k chunks, let $p_i$ be such that the ith chunk contains a fraction of pi of the input dataset.</description>
    </item>
    
    <item>
      <title>Association：Assignment</title>
      <link>https://www.m1sty.com/2021/dm_association_3_assignment/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_3_assignment/</guid>
      <description>Association Frequent Itemsets Qustion 1 Qustion 1-1  Table 1 shows a list of baskets as well as the items they contain. For example, this could be the set of products bought by each customer during a single trip to a grocery store. Using the A-priori algorithm, find all frequent itemsets with support threshold 0.4 (i.e. in this example they occur at least 40% of 7 times, i.e. at least three times.</description>
    </item>
    
    <item>
      <title>Association：Supplement</title>
      <link>https://www.m1sty.com/2021/dm_association_4_more/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_4_more/</guid>
      <description>Association 《数据挖掘概念与技术》 第6章小结  大量数据中的频繁模式、关联和相关关系的发现在选择性销售、决策分析和商务管理方面是有用的。一个流行的应用领域是购物篮分析，通过搜索经常一起(或依次)购买的商品的集合，研究顾客的购买习惯。 关联规则挖掘首先找出频繁项集(项的集合，如A和B，满足最小支持度阈值，或任务相关元组的百分比)，然后，由它们产生形如A→B的强关联规则。这些规则还满足最小置信度阈值(预定义的、在满足A的条件下满足B的概率)。可以进一步分析关联，发现项集A和B之间具有统计相关性的相关规则。 对于频繁项集挖掘，已经开发了许多有效的、可伸缩的算法，由它们可以导出关联和相关规则。这些算法可以分成三类：(1)类Apriori算法；(2)基于频繁模式增长的算法，如FP-growth；(3)使用垂直数据格式的算法。 Apriori算法是为布尔关联规则挖掘频繁项集的原创性算法。它逐层进行挖掘，利用先验性质：频繁项集的所有非空子集也都是频繁的。在第k次迭代(k≥2)，它根据频繁(k-1)项集形成k项集候选，并扫描数据库一次，找出完整的频繁k项集的集合L。使用涉及散列和事务压缩技术的变形使得过程更有效。其他变形包括划分数据(对每分区挖掘,然后合并结果)和抽样数据 (对数据子集挖掘)。这些变形可以将数据扫描次数减少到一两次。 频繁模式增长(FP-growth)是一种不产生候选的挖掘频繁项集方法。它构造一个高度压缩的数据结构(FP树)，压缩原来的事务数据库。与类Apriori方法使用产生-测试策略不同，它聚焦于频繁模式(段)增长，避免了高代价的候选产生，可获得更好的效率。 使用垂直效据格式挖掘频繁模式(ECLAT)将给定的、用TID-项集形式的水平数据格式事务数据集变换成项-TID集合形式的垂直数据格式。它根据先验性质和附加的优化技术(如differ)通过取TID-集的交，对变换后的数据集进行挖掘。 并非所有的强关联规则都是有趣的。因此,应当用模式评估度量来扩展支持度-置信度框架，促进更有趣的规则的挖掘，以产生更有意义的相关规则。一种度量是零不变的，如果它的值不受零事务（即不包含所考虑项集的事务）的影响。在许多模式评估度量中,我们考察了提升度、X、全置信度、最大置信度、 Kuczynski和余弦，并且说明只有后4种是零不变的。我们建议把Kuczynski度量与不平衡比一起使用，提供项集间的模式联系。  第7章小结  频繁模式挖掘的研究范围已经远远超第6章介绍的挖掘频繁项集和关联的基本概念和方法。本章给出了一个该领域的路线图，其中主题按照可挖掘的模式和规则的类型、挖掘方法和应用组织。 除了挖掘基本的频繁项集和关联外，还可以挖掘高级的模式形式，如多层关联和多维关联、量化关联规则、稀有模式和负模式。还可以挖掘高维模式、压缩的或近似的模式。 多层关联涉及多个抽象层中的数据（例如，“买计算机”和“买便携式计算机”）。这些可以使用多个最小支持度阀值挖掘。多维关联包含多个维。挖掘这种关联的技术因如何处理重复谓词而异。量化关联规则涉及量化属性。离散化、聚类和揭示异常行为的统计分析可以与模式挖掘过程集成在一起。 稀有模式很少出现但特别有趣。负模式是其成员呈现负相关行为的模式。应该小心定义负模式，考虑零不变性性质。稀有模式和负模式可能凸显数据的异常行为，这可能很有趣。 基于约束的挖掘策略可以用来引导挖掘过程，挖掘与用户只管一致或满足某些约束的模式。许多用户制定的约束都可以推进到挖掘过程中。约束可以分为模式剪枝约束和数据剪枝约束，这些约束的性质包括单调性、反单调性、数据反单调性和简洁性。具有这些性质的约束可以正确地集成到数据挖掘过程中。 已经为高维空间中的模式挖掘开发了一些方法，包括为挖掘维数很大但元组很少的数据集（如微阵列数据）的基于行枚举的模式增长方法，以及通过模式融合方法挖掘巨型模式（即非常长的模式）。 为了减少挖掘返回的模式数量，我们可以代之以挖掘压缩模式或近似模式。压缩模式可以通过基于聚类概念定义代表模式来挖掘，而近似模式可以通过提取感知冗余的top-k模式（即k个代表模式的小集合，它们不仅具有高显著性，而且相互之间低冗余）来挖掘。 可以产生语义注解，帮助用户理解发现的频繁模式的含义。这样的注解蕾丝词典，提供关于项的语义信息。这些信息包括语境提示符（例如，指示模式语境的术语）/最具代表性的事务（例如，包括该术语的片段或语句）和语义最相似的模式。这种注解从不同角度提供了模式的语境视图，有助于理解它们。 频繁模式挖掘具有形形色色的应用，涵盖从基于模式的数据清理，到基于模式的分类、聚类、离群点或异常分析。  </description>
    </item>
    
    <item>
      <title>Association：Practise</title>
      <link>https://www.m1sty.com/2021/dm_association_5_practise/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_5_practise/</guid>
      <description>#we run apriori on the order_data.csv file import math import pandas as pd from mlxtend.preprocessing import TransactionEncoder from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules data = pd.read_csv(r&amp;#34;order_data.csv&amp;#34;,delimiter=&amp;#34; &amp;#34;,header=None) #preprocessing: change to one hot encoding so as to be able to use apriori from mlxtend d=data.values.tolist() #removing nan values for i in range(len(d)): j=0 while(True): if (type(d[i][j])==float and math.isnan(d[i][j])) : del d[i][j] j-=1 j+=1 if (j&amp;gt;len(d[i])-1): break te = TransactionEncoder() te_ary = te.</description>
    </item>
    
    <item>
      <title>Pre-processing</title>
      <link>https://www.m1sty.com/2021/dm_0_clear/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_0_clear/</guid>
      <description>常用工具 numpy 构建数组   Numpy中常用的数据结构是ndarray格式
  使用array函数创建，语法格式为array(列表或元组)
  可以使用其他函数例如arange、linspace、zeros等创建
  import numpy as np arr1 = np.array([-9,7,4,3]) np.arange(0,10,1) np.linspace(1,10,10) np.zeros (1,5) 常用方法   常用方法名称：ndim、shape、size、dtype、运算
  数组访问方法：array$[行，列]$
  排序  sort函数：从小到大进行排序 argsort函数：返回的是数据中, 从小到大的索引值  s = np.array([1,2,3,4,3,1,2,2,4,6,7,2,4,8,4,5]) np.sort(s) np.argsort(s) 搜索 np.where np.extract np.where(s&amp;gt;3,1,-1) np.extract(s&amp;gt;3,s) pandas 构建数组（series） series1 = pd.Series([2.8,3.01,8.99,8.59,5.18]) series2 = pd.Series([2.8,3.01,8.99,8.59,5.18],index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e&amp;#39;],name =&amp;#39;这是一个series’)  series3 = pd.Series(np.array((2.8,3.10,8.99,8.59,5.18)),index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e’]) series4 = pd.Series({&amp;#39;北京&amp;#39;:2.8,&amp;#39;上海&amp;#39;:3.01,&amp;#39;广东&amp;#39;:8.99,&amp;#39;江苏&amp;#39;:8.59,&amp;#39;浙江&amp;#39;:5.18}) 构建数组（dataframe） list1 = [[&amp;#39;张三&amp;#39;,23,&amp;#39;男&amp;#39;],[&amp;#39;李四&amp;#39;,27,&amp;#39;女&amp;#39;],[&amp;#39;王二&amp;#39;,26,&amp;#39;女&amp;#39;]]#使用嵌套列表 df1 = pd.</description>
    </item>
    
    <item>
      <title>SQL面试必会50题</title>
      <link>https://www.m1sty.com/2020/database_sql_50/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_50/</guid>
      <description>材料 题源+数据 SQL面试必会50题
表关系  题解 01-10 1. 查询课程编号为“01”的课程比“02”的课程成绩高的所有学生的学号 SELECT st.s_id, a.s_score, b.s_score FROM student st INNER JOIN (SELECT s_id, s_score FROM score WHERE c_id = &amp;#34;01&amp;#34;) as a on a.s_id = st.`s_id` INNER JOIN (SELECT s_id, s_score FROM score WHERE c_id = &amp;#34;02&amp;#34;) as b on b.s_id = st.`s_id` WHERE a.s_score &amp;gt; b.s_score; 2. 查询平均成绩大于60分的学生的学号和平均成绩 SELECT distinct s_id, AVG(s_score) as avg1 FROM score Group by S_id having avg1 &amp;gt; 60 3.</description>
    </item>
    
    <item>
      <title>SQL语句复习</title>
      <link>https://www.m1sty.com/2020/database_sql_notes2/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_notes2/</guid>
      <description>DDL &amp;amp; DML 库操作 创建数据库 CREATE DATABASE database-name
删除数据库 drop database dbname
分离数据库 sp_detach_db
附加数据库 sp_attach_db （后接表明，附加需要完整的路径名）
修改数据库名称 sp_renamedb &amp;lsquo;old_name&amp;rsquo;, &amp;lsquo;new_name&amp;rsquo;
表操作 创建新表 create table tabname(col1 type1 [not null] [primary key],col2 type2 [not null],..)
根据已有的表创建新表 A：create table tab_new like tab_old
B：create table tab_new as select col1,col2… from tab_old definition only
删除表 drop table tabname
增加列 Alter table tabname add column col type
添加/删除主键 Alter table tabname add primary key(col)
Alter table tabname drop primary key(col)</description>
    </item>
    
    <item>
      <title>SQL基础知识</title>
      <link>https://www.m1sty.com/2020/database_sql_notes/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_notes/</guid>
      <description>表操作 创建表 create table 表名（字段名称 字段类型 约束，……） 字符类型  character 字符串  char(size) 保存固定长度的字符串 varchar(n) 可变长度的字符_最多8000个字符 text 可变长度的字符串_最多2GB字符数据   unicode 字符串  nchar(n) 固定长度的Unicode数据_最多4000个字符 nvarchar(n) 可变长度的Unicode数据_最多4000个字符 ntext 可变长度的Unicode数据_最多2GB字符数据   Binary 类型  bit 允许0/1/null binary(n) 固定长度的二进制数据_最多8000字节 varbinary(n) 可变长度的二进制数据_最多8000字节 image 可变长度的二进制数据_最多2GB   Number 类型  tinyint 允许从0到255的所有数字 int 允许从-2,147,483,648到2,147,483,647的所有数字_占4字节 bigint -9,223,372,036,854,775,808到9,223,372,036,854,775,807范围内数字_占8字节 float 从-1.79E+308到1.79E+308的浮动精度数字数据 real 从-3.40E+38到3.40E+38的浮动精度数字数据 money 10进制货币数据   Date 类型  datetime 从1753年1月1日到9999年年12月31日，精度为3.33毫秒_8bytes date 仅储存日期。从0001年1月1日到9999年12月31日_3bytes   其他数据类型  uniqueidentifler 存储全局标识符（GUID） xml 存储XML格式化数据_最多2GB cursor 存储对用于数据库操作的指针的引用   常见的字符类型选择  字符类型建议采用varchar/nvarchar数据类型 全额货币建议采用money数据类型 自增长标识建议采用bigint数据类型（int类型限制） 时间类型建议采用datetime数据类型 尽量不用text、ntext、image 尽量不用xml、varchar(max)、nvarchar(max)    不同数据库数据字符类型区别  https://www.</description>
    </item>
    
    <item>
      <title>数据分析师学习路径</title>
      <link>https://www.m1sty.com/2020/overview_data-analyst_map/</link>
      <pubDate>Thu, 24 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/overview_data-analyst_map/</guid>
      <description></description>
    </item>
    
    <item>
      <title>牛客网数据库_错题集</title>
      <link>https://www.m1sty.com/2020/database_sql_nowcoder/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/database_sql_nowcoder/</guid>
      <description>语法问题 删除 如果要从数据库中删除触发器，应该使用SQL语言的命令：（B）
 A.DELETE TRIGGER B.DROP TRIGGER C.DISABLE TRIGGER D.REMOVE TRIGGER  Notes: 删除触发器: DROP TRIGGER &amp;lt;触发器名&amp;gt; ON &amp;lt;表名&amp;gt;
Drop:删除数据表或数据库，或删除数据表字段
Remove:删除数据库文件
Truncate：删除数据表中的数据（仅数据表中的数据，不删除表）
delete和drop最本质的区别在于，delete是数据操纵语言，即DML，而drop是数据定义语言，即DDL。因此，当我们需要删除或者创建一个东西，如表/视图/触发器等等，用的是数据定义语言。当我们对已经存在的表/视图/触发器进行修改/更新时，用的是数据操纵语言。以表为例，如果你不想将表真的删掉，只是想删除其中某些特定的记录，则应该用delete，此时，表的其他数据以及表的结构还在。
权限 收回从u1创建表的权限：（B）
 A.revoke create table to u1 B.revoke create table from u1 C.revoke create table from u1 with grant option D.deny create table to u1  Notes: with grant option 权限传递 使用这个子句时将允许用户将其权限分配给他人
子查询： 在SQL语言中，子查询是： (D)
 A.返回单表中数据子集的查询语言 B.选取多表中字段子集的查询语句 C.选取单表中字段子集的查询语句 D.嵌入到另一个查询语句之中的查询语句  Notes: 子查询本质上是嵌套进其他SELECT,UPDATE,INSERT,DELETE语句的一个被限制的SELECT语句。
子查询也可以嵌套在其他子查询中,这个嵌套最多可达32层。子查询也叫内部查询(Inner query)或者内部选择(Inner Select),而包含子查询的查询语句也叫做外部查询（Outter)或者外部选择(Outer Select)。</description>
    </item>
    
    <item>
      <title>Web 2.0：A Strategy Guide</title>
      <link>https://www.m1sty.com/2020/business_book_web-2.0-a-strategy-guide/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/business_book_web-2.0-a-strategy-guide/</guid>
      <description>Web 2.0: A Strategy Guide Chapter 1 Users Create Value Flickr and Collective User Value   What is Web2.0
Web 2.0 turbocharges network effects because online users are no longer limited by how many things they can find, see, or down- load off the Web, but rather by how many things they can do, interact, combine, remix, upload, change, and customize for them- selves. This online DIY self-expression benefits businesses and other users, not just individual uploaders.</description>
    </item>
    
    <item>
      <title>Data Application in Enterprise</title>
      <link>https://www.m1sty.com/2020/business_essay_data-application-in-enterprise/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/business_essay_data-application-in-enterprise/</guid>
      <description>截取自HKU课程E-commerce technologies，Case Study，本人撰写部分
Data Applications: Enterprise This chapter will analyze the application of data commercialization in enterprises from the perspectives of large enterprises as well as small/medium-sized enterprises. There are two development trends in the future: vertical integration of industry and enterprise boundary broadening.
Before we get into this section, let&amp;rsquo;s talk about the flywheel effect. The essence of the flywheel effect is to produce motion properties. Once a huge flywheel wants to turn, it needs a vast source of power.</description>
    </item>
    
    <item>
      <title>精益数据分析</title>
      <link>https://www.m1sty.com/2020/business_book_jingyishujufenxi/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2020/business_book_jingyishujufenxi/</guid>
      <description>精益数据分析 先导概念 客户开发法 客户开发方法聚焦于持续地收集用户反馈，这些反馈会对产品和业务的每个阶段产生实质性的影响。
精益创业   客户开发+敏捷软件开发方法+精益生产实践
  “构建-衡量-学习”循环：想法=》构建=》产品=》衡量=》数据=》学习=》想法
  第一部分 精益创业和基本分析技术 精益创业   Airbnb：专人接待式最小可行化产品
 在精益创业理论中，最小可行化产品指足以向市场传达你所主张的价值的最小化产品。但定义中并未对产品的真实程度做出要求。例如，如果你正在考虑创建一种拼车服务，则可以试着用人工牵线搭桥这种原始方式将司机和乘客联系在一起。    数据指标   什么是好的数据指标？
 比较性 简单易懂 比率    什么是正确的数据指标？
 定性指标与量化指标 虚荣指标与可付诸行动的指标（规避虚荣指标） 探索性指标与报告性指标 先见性指标与后见性指标 相关性指标与因果性指标（相关性很好，因果性更佳）    市场细分、同期群分析、A/B测试和多变量分析
  同期群分析
  同期群分析使你能够观察处于生命周期不同阶段客户的行为模式，而非个体的自然生命周期，对所有客户一刀切
  同期群分析适用于营收、客户流失率、口碑的病毒式传播、客户支持成本等数据指标
       精益数据分析周期  精益画布 第二部分 精益分析如何用于创业公司 数据分析框架   精益创业画布模块及相关指标</description>
    </item>
    
  </channel>
</rss>
