<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Practise on M1sty</title>
    <link>https://www.m1sty.com/tags/practise/</link>
    <description>Recent content in Practise on M1sty</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 06 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.m1sty.com/tags/practise/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Clusterings：Practise(K-means)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings_5_practise_k-means/</guid>
      <description>Clusterings K-means聚类的思想和原理 模型介绍 对于监督的数据挖掘算法而言，数据集中需要包含标签变量（即因变量y的值）。但在有些场景下，并没有给定的y值，对于这类数据的建模，一般称为无监督的数据挖掘算法，最典型的当属聚类算法。
K-means聚类算法利用距离远近的思想将目标数据为制定的k个簇，进而使样本呈现簇内差异小，簇间差异大的特征。
聚类步骤  从数据中随机挑选k个样本点作为原始的簇中心 计算剩余样本与簇中心的距离，并把各样本标记为离k个簇中心最近的类别 重新计算各簇中样本点的均值，并以均值作为新的k个簇中心 不断重复第二步和第三步，直到簇中心的变化趋于稳定，形成最终的k个簇  原理介绍 最佳K值的选择 拐点法 簇内离差平方和拐点法的思想很简单，就是在不同的k值下计算簇内利差平方和，然后通过可视化的方法找到“拐点”所对应的k值。当折线图中的斜率由大突然变小时，并且之后的斜率变化缓慢，则认为突然变化的点就是寻找的目标点，因为继续随着簇数k的增加，聚类效果不再有大的变化。
def k_SSE(X,cluster): # 选择连续的K种不同的值 K = range(1,clusters+1) # 构建空列表用于存储总的簇内离差平方和 TSSE = [] for k in K: # 用于存储各个簇内离差平方和 SSE = [] kmeans = KMeans(n_clusters = k) Kmeans.fit(X) # 返回簇标签 labels = Kmeans.labels_ # 返回簇中心 centers = Kmeans.cluster_centers_ # 计算各簇样本的离差平方和，并保存到列表中 for label in set(labels): SEE.append(np.sum((X.loc[labels == label,]-centers[label,:])**2)) # 计算总的簇内离差平方和 TSSE.append(np.sum(SSE)) 轮廓系数法 该方法综合考虑了簇的密集性和分散性两个信息，如果数据集被分割为理想的k各簇，那么对应的簇内样本会很密集，而簇间样本会很分散，轮廓系数的计算公式可以表示为：
其中，a(i)体现了簇内的密集性，代表样本i与同簇内其他样本点距离的平均值；b(i)反映了簇间的分散性，它的计算过程是，样本i与其他非同簇样本点距离的平均值，然后从平均值中挑选出最小值。
当S(i)接近于-1时，说明样本i分配的不合理，需要将分配到其他簇中；当S(i)近似为0时，说明样本i落在了模糊地带，即簇的边界处；当S(i)近似为1时，说明样本i的分配是合理的。
# 构造自定义函数 def k_silhouette(X,clusters): K = range(2,clusters+1) # 构建空列表，用于存储不同簇数下的轮廓系数 S = [] for k in K: kmeans = KMeans(n_clusters = k) Kmenas.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(DBSCAN)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-6_practise_dbscan/</guid>
      <description>Clusterings 熟悉密度聚类中的几个概念 模型介绍   Kmeans聚类存在两个致命缺点，一是聚类效果容易受到异常样本点的影响;二是该算法无法准确地将非球形样本进行合理的聚类。
  基于密度的聚类则可以解决非球形簇的问题，“密度”可以理解为样本点的紧密程度，如果在指定的半径领域内，实际样本量超过给定的最小样本量阈值，则认为是密度高的对象，就可以聚成一个簇。
  概念讲解  点的领域：在某点p处，给定其半径e后，所得到的覆盖区域 核心对象：对于给定的最少样本量MinPts而言，如果某点p的e领域内至少包含MinPts个样本点，则点p就为核心对象。 直接密度可达：假设点p为核心对象，且在点p的e领域内存在点q，则从点p出发到点q是直接密度可达的。 密度可达：假设存在一系列的对象链$P_1$,$P_2$,&amp;hellip;,$P_n$，如果$p_i$是关于半径e和最少样本点MinPts的直接密度可达$P_(i+1)$，则p1密度可达$P_n$。(i = 1,2,&amp;hellip;n) 密度相连：假设点o为核心对象，从点o出发得到两个密度可达点p和点q，则称点p和点q是密度相连的。 聚类的簇：簇包含了最大的密度相连所构成的样本点。 边界点：假设点p为核心对象，在其领域内包含了点b，如果点b为非核心对象，则称其为点p的边界点。 异常点：不属于任何簇的样本点。  理解密度聚类的过程 步骤讲解  为密度聚类算法设置一个合理的半径以及半径领域内所包含的最少样本量MinPts。 从数据集中随机挑选一个样本点p，检验其在半径领域内是否包含制定的最少样本量，如果包含就将其定性为核心对象，并构成一个簇C；否则，重新挑选一个样本点。 对于核心对象p所覆盖的其他样本点q，如果点q对应的半径领域内仍然包含最少样本量MinPts，就将其覆盖的样本点统统归于簇C。 重复步骤（3），将最大的密度相连所包含的样本点聚为一类，形成一个大簇。 完成步骤（4）后，重新回到步骤（2），并重复步骤（3）和（4），直到没有新的样本点可以生成新簇时算法结束。  函数介绍 cluster.DBSCAN(eps=0.5, min_samples=5, metric=‘euclidean’, p=None)   eps:用于设置密度聚类中的e领域，即半径，默认为0.5。
  min_samples:用于设置e领域内最少的样本量，默认为5。
  metric:用于指定计算点之间距离的方法，默认为欧氏距离 。
  p:当参数metric为闵可夫斯基(&amp;lsquo;minkowski&amp;rsquo;)距离时，p=1，表示计算点之间的曼哈顿距离;p=2，表示计算点之间的欧式距离；该参数的默认值为2。
  密度聚类相比Kmeans聚类的优势 球形簇的情况 K-means DBSCAN 非球形簇的情况 K-means DBSCAN DBSCAN难确定半径和MinPts
密度聚类的应用实战 利用自定义球形簇数据对比DBSCAN和K-means # 导入第三方模块 import pandas as pd import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Clusterings：Practise(Hierarchical Clusterings)</title>
      <link>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</link>
      <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_clusterings-7_practise_hierarchical/</guid>
      <description>层次聚类 理论说明 https://blog.csdn.net/shulianghan/article/details/105960850
https://blog.csdn.net/liujh845633242/article/details/103679724
层次聚类更适合小样本；K-Means更适合大样本。
代码实现 # 导入第三方模块 import pandas as pd import numpy as np from sklearn.datasets import make_blobs import matplotlib.pyplot as plt import seaborn as sns from sklearn import cluster # 构造两个球形簇的数据样本点 X,y = make_blobs(n_samples = 2000, centers = [[-1,0],[1,0.5]], cluster_std = [0.2,0.45], random_state = 1234) # 将模拟得到的数组转换为数据框，用于绘图 plot_data = pd.DataFrame(np.column_stack((X,y)), columns = [&amp;#39;x1&amp;#39;,&amp;#39;x2&amp;#39;,&amp;#39;y&amp;#39;]) # 绘制散点图（用不同的形状代表不同的簇） sns.lmplot(&amp;#39;x1&amp;#39;, &amp;#39;x2&amp;#39;, data = plot_data, hue = &amp;#39;y&amp;#39;,markers = [&amp;#39;^&amp;#39;,&amp;#39;o&amp;#39;], fit_reg = False, legend = False) # 显示图形 plt.</description>
    </item>
    
    <item>
      <title>Association：Practise</title>
      <link>https://www.m1sty.com/2021/dm_association_5_practise/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_association_5_practise/</guid>
      <description>#we run apriori on the order_data.csv file import math import pandas as pd from mlxtend.preprocessing import TransactionEncoder from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules data = pd.read_csv(r&amp;#34;order_data.csv&amp;#34;,delimiter=&amp;#34; &amp;#34;,header=None) #preprocessing: change to one hot encoding so as to be able to use apriori from mlxtend d=data.values.tolist() #removing nan values for i in range(len(d)): j=0 while(True): if (type(d[i][j])==float and math.isnan(d[i][j])) : del d[i][j] j-=1 j+=1 if (j&amp;gt;len(d[i])-1): break te = TransactionEncoder() te_ary = te.</description>
    </item>
    
    <item>
      <title>Pre-processing</title>
      <link>https://www.m1sty.com/2021/dm_0_clear/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.m1sty.com/2021/dm_0_clear/</guid>
      <description>常用工具 numpy 构建数组   Numpy中常用的数据结构是ndarray格式
  使用array函数创建，语法格式为array(列表或元组)
  可以使用其他函数例如arange、linspace、zeros等创建
  import numpy as np arr1 = np.array([-9,7,4,3]) np.arange(0,10,1) np.linspace(1,10,10) np.zeros (1,5) 常用方法   常用方法名称：ndim、shape、size、dtype、运算
  数组访问方法：array$[行，列]$
  排序  sort函数：从小到大进行排序 argsort函数：返回的是数据中, 从小到大的索引值  s = np.array([1,2,3,4,3,1,2,2,4,6,7,2,4,8,4,5]) np.sort(s) np.argsort(s) 搜索 np.where np.extract np.where(s&amp;gt;3,1,-1) np.extract(s&amp;gt;3,s) pandas 构建数组（series） series1 = pd.Series([2.8,3.01,8.99,8.59,5.18]) series2 = pd.Series([2.8,3.01,8.99,8.59,5.18],index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e&amp;#39;],name =&amp;#39;这是一个series’)  series3 = pd.Series(np.array((2.8,3.10,8.99,8.59,5.18)),index = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;c&amp;#39;,&amp;#39;d&amp;#39;,&amp;#39;e’]) series4 = pd.Series({&amp;#39;北京&amp;#39;:2.8,&amp;#39;上海&amp;#39;:3.01,&amp;#39;广东&amp;#39;:8.99,&amp;#39;江苏&amp;#39;:8.59,&amp;#39;浙江&amp;#39;:5.18}) 构建数组（dataframe） list1 = [[&amp;#39;张三&amp;#39;,23,&amp;#39;男&amp;#39;],[&amp;#39;李四&amp;#39;,27,&amp;#39;女&amp;#39;],[&amp;#39;王二&amp;#39;,26,&amp;#39;女&amp;#39;]]#使用嵌套列表 df1 = pd.</description>
    </item>
    
  </channel>
</rss>
